{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0813f6e",
   "metadata": {},
   "source": [
    "# GroundThink v6 Hybrid Architecture\n",
    "## GDN + SWA with Diagnostic Instrumentation\n",
    "\n",
    "**Structure:**\n",
    "1. Configuration & Imports\n",
    "2. Core Components (RMSNorm, FFN)\n",
    "3. GatedDeltaNetLayer (GDN) - Recurrent memory\n",
    "4. SlidingWindowAttention (SWA) - Local + Global attention with state cross-attention\n",
    "5. TransparentHybrid - Main model\n",
    "6. **Diagnostic Toolkit** - Probe functions for debugging information flow\n",
    "7. Training Infrastructure\n",
    "8. Analysis & Execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa61ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 0: Configuration & Imports\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fla.ops.gated_delta_rule import chunk_gated_delta_rule\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Dict, Tuple, Literal, Any\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HybridConfig:\n",
    "    \"\"\"\n",
    "    Fully configurable hybrid architecture.\n",
    "    \n",
    "    Layer pattern examples:\n",
    "        'GS'      - 1 GDN, 1 SWA (minimal)\n",
    "        'GGSS'    - 2 GDN, 2 SWA\n",
    "        'GSGSG'   - Interleaved\n",
    "        'GGGSGGGS' - DeepSeek-style ratio\n",
    "    \"\"\"\n",
    "    # Model dimensions\n",
    "    d_model: int = 256\n",
    "    n_heads: int = 8\n",
    "    head_dim: int = 64          # Computed in __post_init__\n",
    "    expand_v: float = 2.0       # Value expansion for GDN state\n",
    "    vocab_size: int = 50257\n",
    "    \n",
    "    # Architecture\n",
    "    layer_pattern: str = \"GS\"\n",
    "    \n",
    "    # SWA config\n",
    "    window_size: int = 512\n",
    "    \n",
    "    # Initialization\n",
    "    init_std: float = 0.02\n",
    "    \n",
    "    # State accumulation strategy: 'replace', 'avg', 'weighted'\n",
    "    state_accumulation: str = 'weighted'\n",
    "    state_weight_new: float = 0.5  # Weight for newer state in weighted mode\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.head_dim = self.d_model // self.n_heads\n",
    "        self.value_dim = int(self.head_dim * self.expand_v)\n",
    "        \n",
    "    @property\n",
    "    def n_layers(self) -> int:\n",
    "        return len(self.layer_pattern)\n",
    "    \n",
    "    @property\n",
    "    def gdn_indices(self) -> List[int]:\n",
    "        return [i for i, t in enumerate(self.layer_pattern) if t == 'G']\n",
    "    \n",
    "    @property\n",
    "    def swa_indices(self) -> List[int]:\n",
    "        return [i for i, t in enumerate(self.layer_pattern) if t == 'S']\n",
    "    \n",
    "    def layer_type(self, idx: int) -> str:\n",
    "        return self.layer_pattern[idx]\n",
    "\n",
    "\n",
    "print(\"Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a89a6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core components loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Core Components\n",
    "# =============================================================================\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    \"\"\"Root Mean Square Layer Normalization.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        norm = x.float().pow(2).mean(-1, keepdim=True).add(self.eps).rsqrt()\n",
    "        return (x.float() * norm).type_as(x) * self.weight\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    \"\"\"SwiGLU Feed-Forward Network.\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: HybridConfig):\n",
    "        super().__init__()\n",
    "        hidden = int(cfg.d_model * 8 / 3)\n",
    "        hidden = ((hidden + 63) // 64) * 64  # Round to 64 for efficiency\n",
    "        \n",
    "        self.w1 = nn.Linear(cfg.d_model, hidden, bias=False)\n",
    "        self.w3 = nn.Linear(cfg.d_model, hidden, bias=False)\n",
    "        self.w2 = nn.Linear(hidden, cfg.d_model, bias=False)\n",
    "        self.norm = RMSNorm(cfg.d_model)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.norm(x)\n",
    "        return x + self.w2(F.silu(self.w1(h)) * self.w3(h))\n",
    "\n",
    "\n",
    "print(\"Core components loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02ede4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GatedDeltaNetLayer loaded (TRUE GATEKEEPER).\n",
      "  - beta_proj.bias = -2.0 → default β ≈ 0.12\n",
      "  - NO beta floor → β can reach near 0\n",
      "  - Model must LEARN to spike β for important tokens\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: GatedDeltaNetLayer - TRUE GATEKEEPER\n",
    "# =============================================================================\n",
    "#\n",
    "# CRITICAL FIXES:\n",
    "# 1. REMOVED: beta = 0.5 + 0.5 * beta (was forcing minimum 50% writes)\n",
    "# 2. CHANGED: bias from +1.0 to -2.0 (closed by default)\n",
    "# 3. REMOVED: distinctiveness heuristic (broken after RMSNorm)\n",
    "#\n",
    "# Result: β can reach near 0, model must LEARN what to remember\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "class GatedDeltaNetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    GDN with TRUE Gatekeeper initialization.\n",
    "    \n",
    "    Beta is LOW by default (sigmoid(-2) ≈ 0.12).\n",
    "    Model must learn to spike beta for important tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: HybridConfig, layer_idx: int):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.layer_idx = layer_idx\n",
    "        \n",
    "        H, K, V = cfg.n_heads, cfg.head_dim, cfg.value_dim\n",
    "        \n",
    "        # Standard projections\n",
    "        self.q_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.k_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.v_proj = nn.Linear(cfg.d_model, H * V, bias=False)\n",
    "        self.o_proj = nn.Linear(H * V, cfg.d_model, bias=False)\n",
    "        \n",
    "        # === GATEKEEPER BETA ===\n",
    "        self.beta_proj = nn.Linear(cfg.d_model, H, bias=True)\n",
    "        # CRITICAL: Negative bias = closed by default\n",
    "        # sigmoid(-2.0) ≈ 0.12, preserves 88% of old memory\n",
    "        nn.init.constant_(self.beta_proj.bias, -2.0)\n",
    "        \n",
    "        # Forget gate\n",
    "        self.g_proj = nn.Linear(cfg.d_model, H, bias=False)\n",
    "        \n",
    "        self.norm = RMSNorm(cfg.d_model)\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        initial_state: Optional[torch.Tensor] = None,\n",
    "        output_state: bool = True\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Dict[str, Any]]:\n",
    "        B, T, D = x.shape\n",
    "        H, K, V = self.cfg.n_heads, self.cfg.head_dim, self.cfg.value_dim\n",
    "        \n",
    "        x_norm = self.norm(x)\n",
    "        \n",
    "        # Project to Q, K, V\n",
    "        q = self.q_proj(x_norm).view(B, T, H, K)\n",
    "        k = self.k_proj(x_norm).view(B, T, H, K)\n",
    "        v = self.v_proj(x_norm).view(B, T, H, V)\n",
    "        \n",
    "        # Normalize K for stability\n",
    "        k = F.normalize(k.float(), p=2, dim=-1).to(x.dtype)\n",
    "        \n",
    "        # === TRUE GATEKEEPER BETA ===\n",
    "        # NO floor! Beta can reach near 0.\n",
    "        # With bias=-2.0, default β ≈ 0.12\n",
    "        beta = torch.sigmoid(self.beta_proj(x_norm))  # [B, T, H] in [0, 1]\n",
    "        \n",
    "        # Forget gate (unchanged)\n",
    "        g = F.logsigmoid(self.g_proj(x_norm))\n",
    "        \n",
    "        # Core delta rule\n",
    "        output, state = chunk_gated_delta_rule(\n",
    "            q, k, v, g, beta,\n",
    "            initial_state=initial_state,\n",
    "            output_final_state=output_state\n",
    "        )\n",
    "        \n",
    "        # Project and residual\n",
    "        output = output.reshape(B, T, H * V)\n",
    "        output = self.o_proj(output)\n",
    "        output = x + output\n",
    "        \n",
    "        # Diagnostics - now β should be LOW for most tokens\n",
    "        diagnostics = {\n",
    "            'beta_mean': beta.mean().item(),\n",
    "            'beta_std': beta.std().item(),\n",
    "            'beta_min': beta.min().item(),\n",
    "            'beta_max': beta.max().item(),\n",
    "            'g_mean': g.exp().mean().item(),\n",
    "            'g_std': g.exp().std().item(),\n",
    "            'state_norm': state.norm().item() if state is not None else 0,\n",
    "            'state_shape': tuple(state.shape) if state is not None else None,\n",
    "        }\n",
    "        \n",
    "        return output, state, diagnostics\n",
    "\n",
    "\n",
    "print(\"GatedDeltaNetLayer loaded (TRUE GATEKEEPER).\")\n",
    "print(\"  - beta_proj.bias = -2.0 → default β ≈ 0.12\")\n",
    "print(\"  - NO beta floor → β can reach near 0\")\n",
    "print(\"  - Model must LEARN to spike β for important tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5b7ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SlidingWindowAttention loaded (DEDICATED SPARSE RETRIEVAL).\n",
      "  - Own global_q_proj (not shared with GDN)\n",
      "  - ReLU sparsity on retrieval query\n",
      "  - Decoupled learning: GDN writes, SWA learns to read\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: SlidingWindowAttention - DEDICATED SPARSE RETRIEVAL\n",
    "# =============================================================================\n",
    "#\n",
    "# KEY CHANGE: SWA gets its OWN query projection for state retrieval.\n",
    "#\n",
    "# Why not reuse GDN's q_proj?\n",
    "# - GDN's q_proj is optimized for the delta rule's internal retrieval\n",
    "# - SWA needs to learn a DIFFERENT way to query the state\n",
    "# - Weight-tying couples two different learning objectives\n",
    "#\n",
    "# Additional: ReLU on retrieval query forces sparsity (pointy attention)\n",
    "# even though linear attention lacks softmax temperature control.\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "class SlidingWindowAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    SWA with dedicated sparse retrieval from GDN state.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: HybridConfig, layer_idx: int):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.layer_idx = layer_idx\n",
    "        H, K, V = cfg.n_heads, cfg.head_dim, cfg.value_dim\n",
    "        \n",
    "        # === LOCAL ATTENTION (unchanged) ===\n",
    "        self.q_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.k_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.v_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.o_proj = nn.Linear(H * K, cfg.d_model, bias=False)\n",
    "        \n",
    "        # === DEDICATED GLOBAL RETRIEVAL ===\n",
    "        # Own query projection for state retrieval\n",
    "        self.global_q_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        nn.init.normal_(self.global_q_proj.weight, std=0.01)  # Small init\n",
    "        \n",
    "        # Output projection for retrieved values\n",
    "        self.retrieval_o_proj = nn.Linear(H * V, cfg.d_model, bias=False)\n",
    "        nn.init.xavier_uniform_(self.retrieval_o_proj.weight, gain=0.5)\n",
    "        \n",
    "        # Gate for retrieval contribution\n",
    "        self.gate_proj = nn.Linear(cfg.d_model, H, bias=True)\n",
    "        nn.init.zeros_(self.gate_proj.weight)\n",
    "        nn.init.constant_(self.gate_proj.bias, 0.0)  # Neutral start\n",
    "        \n",
    "        self.norm = RMSNorm(cfg.d_model)\n",
    "        self.scale = K ** -0.5\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor,\n",
    "        gdn_state: Optional[torch.Tensor] = None,\n",
    "        gdn_q_proj: Optional[nn.Module] = None,  # Ignored - we use our own\n",
    "        return_attn: bool = False\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any], ...]:\n",
    "        B, T, D = x.shape\n",
    "        H = self.cfg.n_heads\n",
    "        K = self.cfg.head_dim\n",
    "        V = self.cfg.value_dim\n",
    "        W = self.cfg.window_size\n",
    "        \n",
    "        x_norm = self.norm(x)\n",
    "        \n",
    "        # === LOCAL ATTENTION ===\n",
    "        q = self.q_proj(x_norm).view(B, T, H, K).transpose(1, 2)\n",
    "        k_local = self.k_proj(x_norm).view(B, T, H, K).transpose(1, 2)\n",
    "        v_local = self.v_proj(x_norm).view(B, T, H, K).transpose(1, 2)\n",
    "        \n",
    "        mask = torch.ones(T, T, device=x.device, dtype=torch.bool)\n",
    "        mask = mask.triu(1) | mask.tril(-W - 1)\n",
    "        \n",
    "        attn_local = (q @ k_local.transpose(-2, -1)) * self.scale\n",
    "        attn_local = attn_local.masked_fill(mask.unsqueeze(0).unsqueeze(0), float('-inf'))\n",
    "        attn_weights_local = F.softmax(attn_local, dim=-1)\n",
    "        local_out = attn_weights_local @ v_local\n",
    "        \n",
    "        local_out = local_out.transpose(1, 2).reshape(B, T, H * K)\n",
    "        local_out = self.o_proj(local_out)\n",
    "        \n",
    "        # === DEDICATED SPARSE RETRIEVAL ===\n",
    "        retrieval_out = torch.zeros(B, T, D, device=x.device, dtype=x.dtype)\n",
    "        attn_weights_global = None\n",
    "        gate_values = torch.full((B, H, T, 1), 0.5, device=x.device, dtype=x.dtype)\n",
    "        \n",
    "        if gdn_state is not None:\n",
    "            state = gdn_state.to(x.dtype)  # [B, H, K, V]\n",
    "            \n",
    "            # === OWN QUERY with ReLU SPARSITY ===\n",
    "            # This makes the query \"pointy\" - only strong signals pass through\n",
    "            q_global = self.global_q_proj(x_norm).view(B, T, H, K).transpose(1, 2)  # [B, H, T, K]\n",
    "            q_global = F.relu(q_global)  # Sparsity: zero out negative values\n",
    "            \n",
    "            # Normalize for stable retrieval\n",
    "            q_global = F.normalize(q_global.float(), p=2, dim=-1).to(x.dtype)\n",
    "            \n",
    "            # === LINEAR RETRIEVAL: State @ q ===\n",
    "            # State: [B, H, K, V], q_global: [B, H, T, K]\n",
    "            # Result: [B, H, T, V]\n",
    "            retrieved = torch.einsum('bhkv,bhtk->bhtv', state, q_global)\n",
    "            \n",
    "            # For diagnostics: approximate attention pattern\n",
    "            state_k_norms = state.norm(dim=-1)  # [B, H, K]\n",
    "            attn_weights_global = torch.einsum('bhtk,bhk->bhtk', q_global.abs(), state_k_norms)\n",
    "            attn_weights_global = F.softmax(attn_weights_global / 0.1, dim=-1)  # Sharp softmax for viz\n",
    "            \n",
    "            # Project retrieved values\n",
    "            retrieved = retrieved.transpose(1, 2).reshape(B, T, H * V)\n",
    "            retrieval_out = self.retrieval_o_proj(retrieved)\n",
    "            \n",
    "            # Learned gate\n",
    "            gate_logits = self.gate_proj(x_norm)\n",
    "            gate = torch.sigmoid(gate_logits)\n",
    "            gate_values = gate.transpose(1, 2).unsqueeze(-1)\n",
    "            \n",
    "            gate_scale = gate.mean(dim=-1, keepdim=True)\n",
    "            retrieval_out = gate_scale * retrieval_out\n",
    "        \n",
    "        # === COMBINE ===\n",
    "        out = x + local_out + retrieval_out\n",
    "        \n",
    "        # Diagnostics\n",
    "        diagnostics = {\n",
    "            'local_attn_entropy': -(attn_weights_local * attn_weights_local.clamp(min=1e-8).log()).sum(-1).mean().item(),\n",
    "            'gate_mean': gate_values.mean().item(),\n",
    "            'gate_std': gate_values.std().item(),\n",
    "            'retrieval_norm': retrieval_out.norm().item(),\n",
    "            'local_norm': local_out.norm().item(),\n",
    "            'global_attn_entropy': (\n",
    "                -(attn_weights_global * attn_weights_global.clamp(min=1e-8).log()).sum(-1).mean().item() \n",
    "                if attn_weights_global is not None else 0\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        if return_attn:\n",
    "            return out, diagnostics, attn_weights_local, attn_weights_global, gate_values\n",
    "        return out, diagnostics\n",
    "\n",
    "\n",
    "print(\"SlidingWindowAttention loaded (DEDICATED SPARSE RETRIEVAL).\")\n",
    "print(\"  - Own global_q_proj (not shared with GDN)\")\n",
    "print(\"  - ReLU sparsity on retrieval query\")\n",
    "print(\"  - Decoupled learning: GDN writes, SWA learns to read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5904fb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransparentHybrid loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: TransparentHybrid Model (Simplified)\n",
    "# =============================================================================\n",
    "#\n",
    "# SWA now has its own retrieval query, so we just pass the state.\n",
    "# No need to pass gdn_q_proj.\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "class TransparentHybrid(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid GDN + SWA model.\n",
    "    \n",
    "    - GDN compresses sequence into state with selective writes\n",
    "    - SWA does local attention + queries state with its own learned projection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: HybridConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Embedding\n",
    "        self.embed = nn.Embedding(cfg.vocab_size, cfg.d_model)\n",
    "        nn.init.normal_(self.embed.weight, std=cfg.init_std)\n",
    "        \n",
    "        # Build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.ffns = nn.ModuleList()\n",
    "        \n",
    "        for i, layer_type in enumerate(cfg.layer_pattern):\n",
    "            if layer_type == 'G':\n",
    "                self.layers.append(GatedDeltaNetLayer(cfg, i))\n",
    "            elif layer_type == 'S':\n",
    "                self.layers.append(SlidingWindowAttention(cfg, i))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {layer_type}\")\n",
    "            self.ffns.append(FFN(cfg))\n",
    "        \n",
    "        self.norm_f = RMSNorm(cfg.d_model)\n",
    "        self.lm_head = nn.Linear(cfg.d_model, cfg.vocab_size, bias=False)\n",
    "        self.lm_head.weight = self.embed.weight  # Tie weights\n",
    "        \n",
    "    def _accumulate_state(\n",
    "        self, \n",
    "        accumulated: Optional[torch.Tensor], \n",
    "        new_state: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Accumulate GDN states based on configured strategy.\"\"\"\n",
    "        if accumulated is None:\n",
    "            return new_state\n",
    "        \n",
    "        strategy = self.cfg.state_accumulation\n",
    "        if strategy == 'replace':\n",
    "            return new_state\n",
    "        elif strategy == 'avg':\n",
    "            return 0.5 * accumulated + 0.5 * new_state\n",
    "        elif strategy == 'weighted':\n",
    "            w = self.cfg.state_weight_new\n",
    "            return (1 - w) * accumulated + w * new_state\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown state accumulation strategy: {strategy}\")\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids: torch.Tensor, \n",
    "        targets: Optional[torch.Tensor] = None,\n",
    "        return_diagnostics: bool = False\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[List[Dict]], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Returns: logits, loss, diagnostics (if requested), final_state\n",
    "        \"\"\"\n",
    "        x = self.embed(input_ids)\n",
    "        accumulated_state = None\n",
    "        all_diagnostics = []\n",
    "        \n",
    "        for i, (layer, ffn) in enumerate(zip(self.layers, self.ffns)):\n",
    "            layer_type = self.cfg.layer_pattern[i]\n",
    "            \n",
    "            if layer_type == 'G':\n",
    "                x, state, diag = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "                accumulated_state = self._accumulate_state(accumulated_state, state)\n",
    "                diag['layer_type'] = 'GDN'\n",
    "            elif layer_type == 'S':\n",
    "                # SWA handles its own retrieval query\n",
    "                x, diag = layer(x, gdn_state=accumulated_state)\n",
    "                diag['layer_type'] = 'SWA'\n",
    "            \n",
    "            x = ffn(x)\n",
    "            diag['layer_idx'] = i\n",
    "            all_diagnostics.append(diag)\n",
    "        \n",
    "        x = self.norm_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        \n",
    "        if return_diagnostics:\n",
    "            return logits, loss, all_diagnostics, accumulated_state\n",
    "        return logits, loss, None, accumulated_state\n",
    "\n",
    "\n",
    "print(\"TransparentHybrid loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1564f7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnostic Toolkit loaded.\n",
      "  - probe_gdn_state_content()\n",
      "  - visualize_swa_state_attention()\n",
      "  - trace_needle_pipeline()\n",
      "  - run_full_diagnostic()\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: DIAGNOSTIC TOOLKIT\n",
    "# =============================================================================\n",
    "# These functions probe the information flow to identify bottlenecks.\n",
    "# Run these AFTER training to understand why NIAH fails.\n",
    "#\n",
    "# Decision Tree:\n",
    "#   1. probe_gdn_state_content() -> Is the needle IN the GDN state?\n",
    "#      - Yes -> Architecture working, tune gate/fusion\n",
    "#      - No  -> Is it being written? Check beta values\n",
    "#               - No write -> Fix GDN write mechanism\n",
    "#               - Written but lost -> Fix SWA query mechanism\n",
    "#\n",
    "#   2. visualize_swa_state_attention() -> Is SWA attending to state?\n",
    "#      - Check attention entropy and head specialization\n",
    "#\n",
    "#   3. trace_needle_pipeline() -> End-to-end similarity tracking\n",
    "# =============================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def probe_gdn_state_content(\n",
    "    model: TransparentHybrid, \n",
    "    input_ids: torch.Tensor, \n",
    "    target_token_pos: int = 32,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Probe 1: Check if specific token information is encoded in GDN state.\n",
    "    \n",
    "    This directly tests the WRITE path: is the GDN storing token-specific\n",
    "    information that can be retrieved later?\n",
    "    \n",
    "    Args:\n",
    "        model: The hybrid model\n",
    "        input_ids: Input sequence [1, T] with a \"needle\" token at target_token_pos\n",
    "        target_token_pos: Position of the needle token to probe for\n",
    "        verbose: Print results\n",
    "        \n",
    "    Returns:\n",
    "        Dict with per-layer retrieval analysis and signal-to-noise ratios\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = {'layers': [], 'summary': {}}\n",
    "    \n",
    "    x = model.embed(input_ids)\n",
    "    accumulated_state = None\n",
    "    needle_id = input_ids[0, target_token_pos].item()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROBE 1: GDN State Content Analysis\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Needle token ID: {needle_id} at position {target_token_pos}\")\n",
    "        print()\n",
    "    \n",
    "    for i, (layer, ffn) in enumerate(zip(model.layers, model.ffns)):\n",
    "        layer_type = model.cfg.layer_pattern[i]\n",
    "        \n",
    "        if layer_type == 'G':\n",
    "            x, layer_state, diag = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "            accumulated_state = model._accumulate_state(accumulated_state, layer_state)\n",
    "            \n",
    "            # Get needle embedding and project through this layer's K projection\n",
    "            needle_embed = model.embed.weight[needle_id]\n",
    "            needle_key = layer.k_proj(needle_embed).view(model.cfg.n_heads, model.cfg.head_dim)\n",
    "            needle_key = F.normalize(needle_key.float(), p=2, dim=-1)\n",
    "            \n",
    "            # Query the state: how much of the needle is retrievable?\n",
    "            # needle_key @ state -> retrieved value\n",
    "            retrieved = torch.einsum('hk,bhkv->bhv', needle_key, layer_state.float())\n",
    "            needle_retrieval_norm = retrieved.norm().item()\n",
    "            \n",
    "            # Compare to random token baseline\n",
    "            rand_token = torch.randint(0, model.cfg.vocab_size, (1,), device=input_ids.device).item()\n",
    "            rand_embed = model.embed.weight[rand_token]\n",
    "            rand_key = layer.k_proj(rand_embed).view(model.cfg.n_heads, model.cfg.head_dim)\n",
    "            rand_key = F.normalize(rand_key.float(), p=2, dim=-1)\n",
    "            rand_retrieved = torch.einsum('hk,bhkv->bhv', rand_key, layer_state.float())\n",
    "            rand_retrieval_norm = rand_retrieved.norm().item()\n",
    "            \n",
    "            snr = needle_retrieval_norm / (rand_retrieval_norm + 1e-8)\n",
    "            \n",
    "            layer_result = {\n",
    "                'layer_idx': i,\n",
    "                'layer_type': 'GDN',\n",
    "                'state_norm': layer_state.norm().item(),\n",
    "                'state_shape': tuple(layer_state.shape),\n",
    "                'needle_retrieval_norm': needle_retrieval_norm,\n",
    "                'random_retrieval_norm': rand_retrieval_norm,\n",
    "                'signal_to_noise': snr,\n",
    "                'beta_mean': diag['beta_mean'],\n",
    "                'beta_std': diag['beta_std'],\n",
    "                'g_mean': diag['g_mean'],\n",
    "            }\n",
    "            results['layers'].append(layer_result)\n",
    "            \n",
    "            if verbose:\n",
    "                status = \"✓\" if snr > 1.0 else \"✗\"\n",
    "                print(f\"  [GDN Layer {i}] {status}\")\n",
    "                print(f\"      State: norm={layer_state.norm().item():.4f}, shape={tuple(layer_state.shape)}\")\n",
    "                print(f\"      Needle Retrieval: {needle_retrieval_norm:.6f}\")\n",
    "                print(f\"      Random Retrieval: {rand_retrieval_norm:.6f}\")\n",
    "                print(f\"      Signal-to-Noise:  {snr:.4f} {'(GOOD)' if snr > 1.0 else '(WEAK)'}\")\n",
    "                print(f\"      β={diag['beta_mean']:.3f}±{diag['beta_std']:.3f}, g={diag['g_mean']:.3f}\")\n",
    "                print()\n",
    "                \n",
    "        elif layer_type == 'S':\n",
    "            x, _ = layer(x, gdn_state=accumulated_state)\n",
    "            results['layers'].append({'layer_idx': i, 'layer_type': 'SWA'})\n",
    "        \n",
    "        x = ffn(x)\n",
    "    \n",
    "    # Summary\n",
    "    gdn_results = [r for r in results['layers'] if r['layer_type'] == 'GDN']\n",
    "    if gdn_results:\n",
    "        avg_snr = sum(r['signal_to_noise'] for r in gdn_results) / len(gdn_results)\n",
    "        max_snr = max(r['signal_to_noise'] for r in gdn_results)\n",
    "        results['summary'] = {\n",
    "            'avg_snr': avg_snr,\n",
    "            'max_snr': max_snr,\n",
    "            'needle_stored': max_snr > 1.0,\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Summary: avg_SNR={avg_snr:.4f}, max_SNR={max_snr:.4f}\")\n",
    "            if max_snr > 1.0:\n",
    "                print(f\"  → Needle IS stored in GDN state\")\n",
    "            else:\n",
    "                print(f\"  → Needle NOT effectively stored (check beta/write mechanism)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_swa_state_attention(\n",
    "    model: nn.Module,\n",
    "    input_ids: torch.Tensor,\n",
    "    target_swa_layer: Optional[int] = None,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Probe 2: Analyze SWA's attention to GDN state.\n",
    "    \n",
    "    UPDATED: Now passes gdn_k_proj for aligned retrieval.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # First pass to get GDN state\n",
    "    x = model.embed(input_ids)\n",
    "    accumulated_state = None\n",
    "    \n",
    "    # Get gdn_q_proj for aligned retrieval\n",
    "    gdn_q_proj = model._get_gdn_q_proj() if hasattr(model, '_get_gdn_q_proj') else None\n",
    "    \n",
    "    # Forward through layers to accumulate state\n",
    "    for i, (layer, ffn) in enumerate(zip(model.layers, model.ffns)):\n",
    "        layer_type = model.cfg.layer_pattern[i]\n",
    "        \n",
    "        if layer_type == 'G':\n",
    "            x, state, _ = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "            accumulated_state = model._accumulate_state(accumulated_state, state)\n",
    "        elif layer_type == 'S':\n",
    "            x, _ = layer(x, gdn_state=accumulated_state, gdn_q_proj=gdn_q_proj)\n",
    "        \n",
    "        x = ffn(x)\n",
    "    \n",
    "    # Now analyze each SWA layer's attention\n",
    "    results = {'layers': [], 'summary': {}}\n",
    "    \n",
    "    x = model.embed(input_ids)\n",
    "    accumulated_state = None\n",
    "    \n",
    "    for i, (layer, ffn) in enumerate(zip(model.layers, model.ffns)):\n",
    "        layer_type = model.cfg.layer_pattern[i]\n",
    "        \n",
    "        if layer_type == 'G':\n",
    "            x, state, _ = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "            accumulated_state = model._accumulate_state(accumulated_state, state)\n",
    "            x = ffn(x)\n",
    "            continue\n",
    "        \n",
    "        # SWA layer - get attention weights WITH aligned retrieval\n",
    "        if target_swa_layer is not None and i != target_swa_layer:\n",
    "            x, _ = layer(x, gdn_state=accumulated_state, gdn_q_proj=gdn_q_proj)\n",
    "            x = ffn(x)\n",
    "            continue\n",
    "        \n",
    "        # Get detailed attention for this SWA layer\n",
    "        out, diag, attn_local, attn_global, gate = layer(\n",
    "            x, \n",
    "            gdn_state=accumulated_state,\n",
    "            gdn_q_proj=gdn_q_proj,  # Pass for aligned retrieval\n",
    "            return_attn=True\n",
    "        )\n",
    "        \n",
    "        if attn_global is None:\n",
    "            x = ffn(out)\n",
    "            continue\n",
    "        \n",
    "        # Analyze global attention\n",
    "        # attn_global: [B, H, T, K] - attention over K state dimensions\n",
    "        H = attn_global.shape[1]\n",
    "        T = attn_global.shape[2]\n",
    "        K = attn_global.shape[3]\n",
    "        \n",
    "        # Focus on final token's attention to state\n",
    "        final_attn = attn_global[0, :, -1, :]  # [H, K]\n",
    "        \n",
    "        # Per-head analysis\n",
    "        head_analysis = []\n",
    "        for h in range(H):\n",
    "            attn_h = final_attn[h]  # [K]\n",
    "            entropy = -(attn_h * attn_h.clamp(min=1e-8).log()).sum().item()\n",
    "            max_attn, max_slot = attn_h.max(dim=0)\n",
    "            head_analysis.append({\n",
    "                'head': h,\n",
    "                'entropy': entropy,\n",
    "                'max_attn': max_attn.item(),\n",
    "                'max_slot': max_slot.item(),\n",
    "            })\n",
    "        \n",
    "        # Average entropy across heads\n",
    "        avg_entropy = sum(h['entropy'] for h in head_analysis) / H\n",
    "        max_entropy = math.log(K)  # Uniform distribution\n",
    "        focus_ratio = 1 - (avg_entropy / max_entropy)\n",
    "        \n",
    "        layer_result = {\n",
    "            'layer_idx': i,\n",
    "            'layer_type': 'SWA',\n",
    "            'local_attn_shape': tuple(attn_local.shape),\n",
    "            'global_attn_shape': tuple(attn_global.shape),\n",
    "            'gate_mean': gate.mean().item(),\n",
    "            'gate_std': gate.std().item(),\n",
    "            'avg_global_entropy': avg_entropy,\n",
    "            'max_possible_entropy': max_entropy,\n",
    "            'focus_ratio': focus_ratio,\n",
    "            'per_head': head_analysis,\n",
    "        }\n",
    "        results['layers'].append(layer_result)\n",
    "        \n",
    "        if verbose:\n",
    "            status = \"✓\" if focus_ratio > 0.2 else \"✗\"\n",
    "            print(f\"\\n  [SWA Layer {i}] {status}\")\n",
    "            print(f\"      Global Attn Shape: {tuple(attn_global.shape)}\")\n",
    "            print(f\"      Gate: mean={gate.mean().item():.3f}, std={gate.std().item():.3f}\")\n",
    "            print(f\"      Avg Entropy: {avg_entropy:.4f} / {max_entropy:.4f} (max)\")\n",
    "            focus_status = \"FOCUSED\" if focus_ratio > 0.2 else \"DIFFUSE\"\n",
    "            print(f\"      Focus Ratio: {focus_ratio:.4f} ({focus_status})\")\n",
    "            print(f\"      Per-head (final token -> state):\")\n",
    "            for h in head_analysis:\n",
    "                print(f\"        H{h['head']}: entropy={h['entropy']:.3f}, max={h['max_attn']:.3f}@slot{h['max_slot']}\")\n",
    "        \n",
    "        x = ffn(out)\n",
    "    \n",
    "    # Summary\n",
    "    if results['layers']:\n",
    "        avg_focus = sum(l['focus_ratio'] for l in results['layers']) / len(results['layers'])\n",
    "        avg_gate = sum(l['gate_mean'] for l in results['layers']) / len(results['layers'])\n",
    "        results['summary'] = {\n",
    "            'avg_focus_ratio': avg_focus,\n",
    "            'avg_gate': avg_gate,\n",
    "            'attention_focused': avg_focus > 0.2,\n",
    "            'using_global': avg_gate > 0.3,\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n  Summary: avg_focus={avg_focus:.4f}, avg_gate={avg_gate:.4f}\")\n",
    "            if avg_focus < 0.2:\n",
    "                print(\"  → SWA attention is DIFFUSE (not learning to query)\")\n",
    "            else:\n",
    "                print(\"  → SWA attention is FOCUSED (learning to query specific slots)\")\n",
    "            if avg_gate > 0.3:\n",
    "                print(\"  → SWA is USING global state (gate > 0.3)\")\n",
    "            else:\n",
    "                print(\"  → SWA is IGNORING global state (gate < 0.3)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "@torch.no_grad()\n",
    "def trace_needle_pipeline(\n",
    "    model: TransparentHybrid, \n",
    "    input_ids: torch.Tensor, \n",
    "    needle_pos: int = 32,\n",
    "    query_pos: int = -1,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Probe 3: Trace needle information through the entire forward pass.\n",
    "    \n",
    "    Tracks cosine similarity between the query position's representation\n",
    "    and the needle token's embedding as it evolves through layers.\n",
    "    \n",
    "    Look for:\n",
    "        - Similarity INCREASE at SWA layers (retrieval working)\n",
    "        - State containing needle at GDN layers\n",
    "    \n",
    "    Args:\n",
    "        model: The hybrid model\n",
    "        input_ids: Input sequence [1, T] with needle at needle_pos\n",
    "        needle_pos: Position of needle token\n",
    "        query_pos: Position to track (default: -1 = final position)\n",
    "        verbose: Print results\n",
    "        \n",
    "    Returns:\n",
    "        Dict with per-layer trajectory\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    T = input_ids.shape[1]\n",
    "    if query_pos < 0:\n",
    "        query_pos = T + query_pos  # Convert negative index\n",
    "    \n",
    "    needle_id = input_ids[0, needle_pos].item()\n",
    "    needle_embed = model.embed.weight[needle_id].float()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROBE 3: Needle Pipeline Trace\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Needle: token {needle_id} @ pos {needle_pos}\")\n",
    "        print(f\"Query:  pos {query_pos}\")\n",
    "        print(f\"Distance: {query_pos - needle_pos} tokens\\n\")\n",
    "    \n",
    "    x = model.embed(input_ids)\n",
    "    accumulated_state = None\n",
    "    trajectory = []\n",
    "    \n",
    "    # Initial similarity\n",
    "    init_rep = x[0, query_pos].float()\n",
    "    init_sim = F.cosine_similarity(init_rep, needle_embed, dim=0).item()\n",
    "    trajectory.append({\n",
    "        'stage': 'embed',\n",
    "        'layer_idx': -1,\n",
    "        'layer_type': 'EMBED',\n",
    "        'similarity': init_sim,\n",
    "        'delta': 0.0,\n",
    "    })\n",
    "    \n",
    "    for i, (layer, ffn) in enumerate(zip(model.layers, model.ffns)):\n",
    "        layer_type = model.cfg.layer_pattern[i]\n",
    "        \n",
    "        pre_rep = x[0, query_pos].float()\n",
    "        pre_sim = F.cosine_similarity(pre_rep, needle_embed, dim=0).item()\n",
    "        \n",
    "        state_needle_norm = None\n",
    "        \n",
    "        if layer_type == 'G':\n",
    "            x, layer_state, diag = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "            accumulated_state = model._accumulate_state(accumulated_state, layer_state)\n",
    "            \n",
    "            # Check if needle is in state\n",
    "            needle_key = layer.k_proj(needle_embed.to(x.dtype)).view(model.cfg.n_heads, model.cfg.head_dim)\n",
    "            needle_key = F.normalize(needle_key.float(), p=2, dim=-1)\n",
    "            retrieved = torch.einsum('hk,bhkv->bhv', needle_key, layer_state.float())\n",
    "            state_needle_norm = retrieved.norm().item()\n",
    "            \n",
    "        elif layer_type == 'S':\n",
    "            x, diag = layer(x, gdn_state=accumulated_state)\n",
    "        \n",
    "        x = ffn(x)\n",
    "        \n",
    "        post_rep = x[0, query_pos].float()\n",
    "        post_sim = F.cosine_similarity(post_rep, needle_embed, dim=0).item()\n",
    "        delta = post_sim - pre_sim\n",
    "        \n",
    "        layer_result = {\n",
    "            'stage': f'layer_{i}',\n",
    "            'layer_idx': i,\n",
    "            'layer_type': layer_type,\n",
    "            'pre_sim': pre_sim,\n",
    "            'post_sim': post_sim,\n",
    "            'delta': delta,\n",
    "            'state_needle_norm': state_needle_norm,\n",
    "        }\n",
    "        trajectory.append(layer_result)\n",
    "        \n",
    "        if verbose:\n",
    "            arrow = \"↑\" if delta > 0.01 else (\"↓\" if delta < -0.01 else \"→\")\n",
    "            type_str = 'GDN' if layer_type == 'G' else 'SWA'\n",
    "            state_str = f\", state_needle={state_needle_norm:.4f}\" if state_needle_norm else \"\"\n",
    "            print(f\"  L{i:2d} [{type_str}]: {pre_sim:+.4f} {arrow} {post_sim:+.4f} (Δ{delta:+.4f}){state_str}\")\n",
    "    \n",
    "    # Summary\n",
    "    final_sim = trajectory[-1]['post_sim']\n",
    "    total_delta = final_sim - init_sim\n",
    "    \n",
    "    # Find where biggest gains/losses happen\n",
    "    max_gain = max(t['delta'] for t in trajectory[1:])\n",
    "    max_loss = min(t['delta'] for t in trajectory[1:])\n",
    "    max_gain_layer = [t for t in trajectory[1:] if t['delta'] == max_gain][0]\n",
    "    max_loss_layer = [t for t in trajectory[1:] if t['delta'] == max_loss][0]\n",
    "    \n",
    "    results = {\n",
    "        'trajectory': trajectory,\n",
    "        'summary': {\n",
    "            'initial_sim': init_sim,\n",
    "            'final_sim': final_sim,\n",
    "            'total_delta': total_delta,\n",
    "            'max_gain': max_gain,\n",
    "            'max_gain_layer': max_gain_layer['layer_idx'],\n",
    "            'max_gain_type': max_gain_layer['layer_type'],\n",
    "            'max_loss': max_loss,\n",
    "            'max_loss_layer': max_loss_layer['layer_idx'],\n",
    "            'retrieval_working': total_delta > 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n  Summary:\")\n",
    "        print(f\"    Initial → Final: {init_sim:+.4f} → {final_sim:+.4f} (Δ{total_delta:+.4f})\")\n",
    "        print(f\"    Max gain: {max_gain:+.4f} at L{max_gain_layer['layer_idx']} [{max_gain_layer['layer_type']}]\")\n",
    "        print(f\"    Max loss: {max_loss:+.4f} at L{max_loss_layer['layer_idx']} [{max_loss_layer['layer_type']}]\")\n",
    "        if total_delta > 0:\n",
    "            print(f\"    → Needle info IS reaching query position\")\n",
    "        else:\n",
    "            print(f\"    → Needle info NOT reaching query position\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_full_diagnostic(\n",
    "    model: TransparentHybrid,\n",
    "    seq_len: int = 128,\n",
    "    needle_pos: int = 32,\n",
    "    needle_token: int = 50000,\n",
    "    device: str = 'cuda'\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run all three diagnostic probes and return combined results.\n",
    "    \n",
    "    This is your one-stop diagnostic function. Run this after training\n",
    "    to understand where the information pipeline is breaking.\n",
    "    \"\"\"\n",
    "    # Create test sequence with needle\n",
    "    tokens = torch.randint(1000, 10000, (1, seq_len), device=device)\n",
    "    tokens[0, needle_pos] = needle_token\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*60)\n",
    "    print(\"# FULL DIAGNOSTIC SUITE\")\n",
    "    print(\"#\"*60)\n",
    "    print(f\"Sequence length: {seq_len}\")\n",
    "    print(f\"Needle token: {needle_token} @ position {needle_pos}\")\n",
    "    print(f\"Query position: {seq_len - 1} (final)\")\n",
    "    \n",
    "    # Run probes\n",
    "    probe1 = probe_gdn_state_content(model, tokens, target_token_pos=needle_pos)\n",
    "    probe2 = visualize_swa_state_attention(model, tokens)\n",
    "    probe3 = trace_needle_pipeline(model, tokens, needle_pos=needle_pos)\n",
    "    \n",
    "    # Diagnosis\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DIAGNOSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    needle_stored = probe1['summary'].get('needle_stored', False)\n",
    "    attention_focused = probe2['summary'].get('attention_focused', False)\n",
    "    using_global = probe2['summary'].get('using_global', False)\n",
    "    retrieval_working = probe3['summary'].get('retrieval_working', False)\n",
    "    \n",
    "    if needle_stored and attention_focused and retrieval_working:\n",
    "        print(\"✓ Architecture appears to be WORKING\")\n",
    "        print(\"  Focus on: Gate tuning, fusion weights, training dynamics\")\n",
    "    elif not needle_stored:\n",
    "        print(\"✗ Problem: GDN NOT storing needle\")\n",
    "        print(\"  → Check beta (write strength) values\")\n",
    "        print(\"  → Check beta_proj initialization\")\n",
    "        print(\"  → May need stronger write gate bias\")\n",
    "    elif needle_stored and not attention_focused:\n",
    "        print(\"✗ Problem: SWA attention is DIFFUSE\")\n",
    "        print(\"  → Needle is stored but SWA can't find it\")\n",
    "        print(\"  → Check state_k_proj / state_v_proj initialization\")\n",
    "        print(\"  → Consider attentional reading instead of additive fusion\")\n",
    "    elif needle_stored and attention_focused and not using_global:\n",
    "        print(\"✗ Problem: SWA IGNORING global state\")\n",
    "        print(\"  → Gate is too low\")\n",
    "        print(\"  → Consider initializing gate bias positive\")\n",
    "        print(\"  → Or switch to learned gating mechanism\")\n",
    "    else:\n",
    "        print(\"? Unclear failure mode - review individual probe results\")\n",
    "    \n",
    "    return {\n",
    "        'probe1_gdn_state': probe1,\n",
    "        'probe2_swa_attention': probe2,\n",
    "        'probe3_pipeline': probe3,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Diagnostic Toolkit loaded.\")\n",
    "print(\"  - probe_gdn_state_content()\")\n",
    "print(\"  - visualize_swa_state_attention()\")\n",
    "print(\"  - trace_needle_pipeline()\")\n",
    "print(\"  - run_full_diagnostic()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1785957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training infrastructure loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Training Infrastructure\n",
    "# =============================================================================\n",
    "\n",
    "def simple_niah(\n",
    "    model: TransparentHybrid, \n",
    "    seq_len: int = 128, \n",
    "    needle_pos: int = 32, \n",
    "    needle_token: int = 50000,\n",
    "    n_trials: int = 20\n",
    ") -> List[Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Needle-In-A-Haystack test.\n",
    "    \n",
    "    Insert a rare token early in sequence, check if model assigns\n",
    "    higher probability to it at the final position.\n",
    "    \n",
    "    Returns:\n",
    "        List of trial results with needle probability and ratio vs random\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_trials):\n",
    "            tokens = torch.randint(1000, 10000, (1, seq_len), device=next(model.parameters()).device)\n",
    "            tokens[0, needle_pos] = needle_token\n",
    "            \n",
    "            logits, _, _, state = model(tokens, return_diagnostics=True)\n",
    "            \n",
    "            final_probs = F.softmax(logits[0, -1].float(), dim=-1)\n",
    "            needle_prob = final_probs[needle_token].item()\n",
    "            random_baseline = 1.0 / model.cfg.vocab_size\n",
    "            \n",
    "            results.append({\n",
    "                'needle_prob': needle_prob,\n",
    "                'ratio': needle_prob / random_baseline,\n",
    "                'state_norm': state.norm().item() if state is not None else 0,\n",
    "            })\n",
    "    \n",
    "    avg_ratio = sum(r['ratio'] for r in results) / len(results)\n",
    "    print(f\"NIAH: {avg_ratio:.4f}x random ({'PASS' if avg_ratio > 1.0 else 'FAIL'})\")\n",
    "    return results\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Simple streaming data loader for training.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        token_tensor: torch.Tensor, \n",
    "        batch_size: int = 4, \n",
    "        seq_len: int = 128\n",
    "    ):\n",
    "        self.tokens = token_tensor\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def get_batch(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        ix = torch.randint(0, len(self.tokens) - self.seq_len - 1, (self.batch_size,))\n",
    "        x = torch.stack([self.tokens[i:i+self.seq_len] for i in ix])\n",
    "        y = torch.stack([self.tokens[i+1:i+self.seq_len+1] for i in ix])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: TransparentHybrid,\n",
    "    data_loader: DataLoader,\n",
    "    steps: int = 10000,\n",
    "    lr: float = 3e-4,\n",
    "    warmup_steps: int = 200,\n",
    "    log_every: int = 100,\n",
    "    niah_every: int = 500,\n",
    "    niah_seq_len: int = 128,\n",
    "    niah_needle_pos: int = 32,\n",
    ") -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Training loop with monitoring.\n",
    "    \n",
    "    Returns:\n",
    "        History dict with loss, NIAH ratios, and diagnostic values\n",
    "    \"\"\"\n",
    "    from torch.optim import AdamW\n",
    "    \n",
    "    opt = AdamW(model.parameters(), lr=lr, betas=(0.9, 0.95), weight_decay=0.1)\n",
    "    \n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    print(f\"\\nTraining {steps} steps\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # LR schedule: linear warmup then cosine decay\n",
    "        if step < warmup_steps:\n",
    "            current_lr = lr * (step + 1) / warmup_steps\n",
    "        else:\n",
    "            progress = (step - warmup_steps) / (steps - warmup_steps)\n",
    "            current_lr = lr * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "        for pg in opt.param_groups:\n",
    "            pg['lr'] = current_lr\n",
    "        \n",
    "        # Forward\n",
    "        x, y = data_loader.get_batch()\n",
    "        logits, loss, diags, state = model(x, y, return_diagnostics=True)\n",
    "        \n",
    "        # Backward\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        \n",
    "        # Track\n",
    "        history['loss'].append(loss.item())\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # Extract diagnostics\n",
    "        gdn_diags = [d for d in diags if d['layer_type'] == 'GDN']\n",
    "        swa_diags = [d for d in diags if d['layer_type'] == 'SWA']\n",
    "        \n",
    "        if gdn_diags:\n",
    "            history['gdn_beta'].append(gdn_diags[0]['beta_mean'])\n",
    "            history['gdn_g'].append(gdn_diags[0]['g_mean'])\n",
    "            history['state_norm'].append(gdn_diags[0]['state_norm'])\n",
    "        if swa_diags:\n",
    "            history['swa_gate'].append(swa_diags[0]['gate_mean'])\n",
    "        \n",
    "        # Log\n",
    "        if step % log_every == 0:\n",
    "            elapsed = time.time() - start\n",
    "            tps = (step + 1) * data_loader.batch_size * data_loader.seq_len / elapsed\n",
    "            avg_loss = sum(history['loss'][-50:]) / min(50, len(history['loss']))\n",
    "            \n",
    "            gdn_str = f\"β={gdn_diags[0]['beta_mean']:.3f} g={gdn_diags[0]['g_mean']:.3f}\" if gdn_diags else \"\"\n",
    "            swa_str = f\"gate={swa_diags[0]['gate_mean']:.2f}\" if swa_diags else \"\"\n",
    "            \n",
    "            print(f\"[{step:5d}] loss={avg_loss:.3f} lr={current_lr:.2e} | {gdn_str} {swa_str} | {tps:,.0f} tok/s\")\n",
    "        \n",
    "        # NIAH check\n",
    "        if (step + 1) % niah_every == 0:\n",
    "            model.eval()\n",
    "            niah = simple_niah(model, seq_len=niah_seq_len, needle_pos=niah_needle_pos, n_trials=30)\n",
    "            avg_ratio = sum(r['ratio'] for r in niah) / len(niah)\n",
    "            history['niah_ratio'].append((step + 1, avg_ratio))\n",
    "            model.train()\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"\\nTraining complete in {elapsed/60:.1f} min\")\n",
    "    print(f\"Final loss: {sum(history['loss'][-50:])/50:.3f}\")\n",
    "    \n",
    "    return dict(history)\n",
    "\n",
    "\n",
    "print(\"Training infrastructure loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1293a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Building TransparentHybrid\n",
      "============================================================\n",
      "\n",
      "Architecture: GS\n",
      "  GDN layers: [0]\n",
      "  SWA layers: [1]\n",
      "\n",
      "Parameters:\n",
      "  total : 14.807M\n",
      "  gdn   : 0.398M\n",
      "  swa   : 0.461M\n",
      "  ffn   : 1.082M\n",
      "  embed : 12.866M\n",
      "  Total:   14.807M\n",
      "============================================================\n",
      "\n",
      "Forward pass OK:\n",
      "  Logits: torch.Size([1, 128, 50257])\n",
      "  Loss: 10.8750\n",
      "  State: torch.Size([1, 8, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: Build & Initialize Model\n",
    "# =============================================================================\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "def count_params_by_type(model):\n",
    "    counts = {\n",
    "        'total': 0,\n",
    "        'gdn': 0,\n",
    "        'swa': 0,\n",
    "        'ffn': 0,\n",
    "        'embed': 0,\n",
    "    }\n",
    "    for name, param in model.named_parameters():\n",
    "        counts['total'] += param.numel()\n",
    "        if 'layers' in name:\n",
    "            layer_idx = int(name.split('.')[1])\n",
    "            layer_type = model.cfg.layer_pattern[layer_idx]\n",
    "            if layer_type == 'G':\n",
    "                counts['gdn'] += param.numel()\n",
    "            elif layer_type == 'S':\n",
    "                counts['swa'] += param.numel()\n",
    "        elif 'ffns' in name:\n",
    "            counts['ffn'] += param.numel()\n",
    "        elif 'embed' in name or 'lm_head' in name:\n",
    "            counts['embed'] += param.numel()\n",
    "    return counts\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Building TransparentHybrid\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "cfg = HybridConfig(\n",
    "    d_model=256,\n",
    "    n_heads=8,\n",
    "    layer_pattern=\"GS\",\n",
    "    window_size=128,\n",
    "    state_accumulation='weighted',\n",
    "    state_weight_new=0.5,\n",
    ")\n",
    "\n",
    "model = TransparentHybrid(cfg).cuda().bfloat16()\n",
    "params = count_params(model)\n",
    "\n",
    "print(f\"\\nArchitecture: {cfg.layer_pattern}\")\n",
    "print(f\"  GDN layers: {cfg.gdn_indices}\")\n",
    "print(f\"  SWA layers: {cfg.swa_indices}\")\n",
    "print(f\"\\nParameters:\")\n",
    "param_counts = count_params_by_type(model)\n",
    "for k, v in param_counts.items():\n",
    "    print(f\"  {k:6s}: {v/1e6:.3f}M\")\n",
    "print(f\"  Total:   {params/1e6:.3f}M\")\n",
    "print(\"=\"*60)   \n",
    "\n",
    "# Quick forward pass test\n",
    "x = torch.randint(0, 1000, (1, 128), device='cuda')\n",
    "y = torch.randint(0, 1000, (1, 128), device='cuda')\n",
    "logits, loss, diags, state = model(x, y, return_diagnostics=True)\n",
    "\n",
    "print(f\"\\nForward pass OK:\")\n",
    "print(f\"  Logits: {logits.shape}\")\n",
    "print(f\"  Loss: {loss.item():.4f}\")\n",
    "print(f\"  State: {state.shape if state is not None else None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f4d358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training diagnostic baseline:\n",
      "\n",
      "NIAH: 1.1162x random (PASS)\n",
      "\n",
      "############################################################\n",
      "# FULL DIAGNOSTIC SUITE\n",
      "############################################################\n",
      "Sequence length: 128\n",
      "Needle token: 50000 @ position 32\n",
      "Query position: 127 (final)\n",
      "\n",
      "============================================================\n",
      "PROBE 1: GDN State Content Analysis\n",
      "============================================================\n",
      "Needle token ID: 50000 at position 32\n",
      "\n",
      "  [GDN Layer 0] ✗\n",
      "      State: norm=2.0766, shape=(1, 8, 32, 64)\n",
      "      Needle Retrieval: 0.307689\n",
      "      Random Retrieval: 0.414493\n",
      "      Signal-to-Noise:  0.7423 (WEAK)\n",
      "      β=0.132±0.065, g=0.500\n",
      "\n",
      "  Summary: avg_SNR=0.7423, max_SNR=0.7423\n",
      "  → Needle NOT effectively stored (check beta/write mechanism)\n",
      "\n",
      "  [SWA Layer 1] ✗\n",
      "      Global Attn Shape: (1, 8, 128, 32)\n",
      "      Gate: mean=0.500, std=0.000\n",
      "      Avg Entropy: 3.4434 / 3.4657 (max)\n",
      "      Focus Ratio: 0.0065 (DIFFUSE)\n",
      "      Per-head (final token -> state):\n",
      "        H0: entropy=3.453, max=0.058@slot1\n",
      "        H1: entropy=3.453, max=0.050@slot10\n",
      "        H2: entropy=3.453, max=0.043@slot11\n",
      "        H3: entropy=3.438, max=0.058@slot11\n",
      "        H4: entropy=3.453, max=0.073@slot17\n",
      "        H5: entropy=3.391, max=0.097@slot10\n",
      "        H6: entropy=3.453, max=0.045@slot17\n",
      "        H7: entropy=3.453, max=0.053@slot18\n",
      "\n",
      "  Summary: avg_focus=0.0065, avg_gate=0.5000\n",
      "  → SWA attention is DIFFUSE (not learning to query)\n",
      "  → SWA is USING global state (gate > 0.3)\n",
      "\n",
      "============================================================\n",
      "PROBE 3: Needle Pipeline Trace\n",
      "============================================================\n",
      "Needle: token 50000 @ pos 32\n",
      "Query:  pos 127\n",
      "Distance: 95 tokens\n",
      "\n",
      "  L 0 [GDN]: -0.0823 ↑ -0.0139 (Δ+0.0684), state_needle=0.3077\n",
      "  L 1 [SWA]: -0.0139 → -0.0228 (Δ-0.0089)\n",
      "\n",
      "  Summary:\n",
      "    Initial → Final: -0.0823 → -0.0228 (Δ+0.0595)\n",
      "    Max gain: +0.0684 at L0 [G]\n",
      "    Max loss: -0.0089 at L1 [S]\n",
      "    → Needle info IS reaching query position\n",
      "\n",
      "============================================================\n",
      "DIAGNOSIS\n",
      "============================================================\n",
      "✗ Problem: GDN NOT storing needle\n",
      "  → Check beta (write strength) values\n",
      "  → Check beta_proj initialization\n",
      "  → May need stronger write gate bias\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: Pre-Training Diagnostics (Optional)\n",
    "# =============================================================================\n",
    "# Run this BEFORE training to establish baseline behavior.\n",
    "# Compare with post-training diagnostics to see what changed.\n",
    "\n",
    "print(\"Pre-training diagnostic baseline:\")\n",
    "print()\n",
    "\n",
    "# Quick NIAH\n",
    "niah_pre = simple_niah(model, seq_len=128, needle_pos=32, n_trials=20)\n",
    "\n",
    "# Full diagnostic\n",
    "pre_diag = run_full_diagnostic(model, seq_len=128, needle_pos=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73d30092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,000,000 tokens\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: Load Data\n",
    "# =============================================================================\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Loading data...\")\n",
    "ds = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\", streaming=True)\n",
    "\n",
    "# Buffer tokens\n",
    "token_buffer = []\n",
    "target_tokens = 2_000_000  # 2M tokens\n",
    "\n",
    "for doc in ds:\n",
    "    toks = tokenizer.encode(doc['text'])\n",
    "    token_buffer.extend(toks)\n",
    "    if len(token_buffer) >= target_tokens:\n",
    "        break\n",
    "\n",
    "token_tensor = torch.tensor(token_buffer[:target_tokens], device='cuda')\n",
    "print(f\"Loaded {len(token_tensor):,} tokens\")\n",
    "\n",
    "# Create data loader\n",
    "data_loader = DataLoader(token_tensor, batch_size=4, seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca8287d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9b: PROPER NIAH TEST + RETRIEVAL TRAINING\n",
    "# =============================================================================\n",
    "#\n",
    "# TWO PARTS:\n",
    "# 1. NIAH test with actual retrieval CUE (not just random tokens)\n",
    "# 2. Synthetic retrieval training data to teach the mechanism\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# =============================================================================\n",
    "# PART 1: PROPER NIAH TEST (with retrieval cue)\n",
    "# =============================================================================\n",
    "\n",
    "def proper_niah_test(\n",
    "    model,\n",
    "    seq_len: int = 128,\n",
    "    needle_pos: int = 32,\n",
    "    n_trials: int = 30,\n",
    "    vocab_size: int = 50257,\n",
    "    cue_token: int = 50250,      # Special token meaning \"retrieve\"\n",
    "    needle_marker: int = 50251,  # Special token marking needle\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    NIAH test with proper retrieval cue.\n",
    "    \n",
    "    Format: [hay] MARKER needle [hay] CUE -> should predict needle\n",
    "    \n",
    "    The CUE token tells the model \"now retrieve what was marked\"\n",
    "    Without this, there's no signal that retrieval is expected.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Random needle (avoid special tokens)\n",
    "        needle_id = torch.randint(1000, vocab_size - 100, (1,)).item()\n",
    "        \n",
    "        # Build sequence: [hay] MARKER needle [hay] CUE\n",
    "        seq = torch.randint(0, vocab_size - 100, (1, seq_len), device=device)\n",
    "        \n",
    "        # Place marker before needle\n",
    "        seq[0, needle_pos - 1] = needle_marker\n",
    "        seq[0, needle_pos] = needle_id\n",
    "        \n",
    "        # Place cue at end (position -2, so -1 is where we predict)\n",
    "        seq[0, -2] = cue_token\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            logits, _, _, _ = model(seq)\n",
    "        \n",
    "        # Check prediction at position after CUE\n",
    "        pred_logits = logits[0, -1, :]  # [vocab_size]\n",
    "        pred_probs = F.softmax(pred_logits, dim=-1)\n",
    "        \n",
    "        needle_prob = pred_probs[needle_id].item()\n",
    "        needle_rank = (pred_probs > needle_prob).sum().item() + 1\n",
    "        \n",
    "        # Compare to random baseline\n",
    "        random_id = torch.randint(1000, vocab_size - 100, (1,)).item()\n",
    "        random_prob = pred_probs[random_id].item()\n",
    "        \n",
    "        ratio = needle_prob / (random_prob + 1e-10)\n",
    "        \n",
    "        results.append({\n",
    "            'needle_id': needle_id,\n",
    "            'needle_prob': needle_prob,\n",
    "            'needle_rank': needle_rank,\n",
    "            'random_prob': random_prob,\n",
    "            'ratio': ratio,\n",
    "            'success': ratio > 1.0,\n",
    "        })\n",
    "    \n",
    "    # Summary\n",
    "    avg_ratio = sum(r['ratio'] for r in results) / len(results)\n",
    "    avg_rank = sum(r['needle_rank'] for r in results) / len(results)\n",
    "    success_rate = sum(r['success'] for r in results) / len(results)\n",
    "    \n",
    "    status = \"PASS\" if avg_ratio > 1.0 else \"FAIL\"\n",
    "    print(f\"NIAH (with cue): {avg_ratio:.4f}x random ({status})\")\n",
    "    print(f\"  Avg needle rank: {avg_rank:.0f} / {vocab_size}\")\n",
    "    print(f\"  Success rate: {success_rate*100:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'avg_ratio': avg_ratio,\n",
    "        'avg_rank': avg_rank,\n",
    "        'success_rate': success_rate,\n",
    "        'trials': results,\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb0ba003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PART 2: SYNTHETIC RETRIEVAL TRAINING DATA\n",
    "# =============================================================================\n",
    "\n",
    "class RetrievalDataGenerator:\n",
    "    \"\"\"\n",
    "    Generates synthetic retrieval training examples.\n",
    "    \n",
    "    Format: [context] MARKER value [distractor] CUE -> value\n",
    "    \n",
    "    This teaches the model:\n",
    "    1. When seeing MARKER, store the next token strongly (spike β)\n",
    "    2. When seeing distractors, preserve state (don't overwrite)\n",
    "    3. When seeing CUE, retrieve and output the marked value\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int = 50257,\n",
    "        marker_token: int = 50251,\n",
    "        cue_token: int = 50250,\n",
    "        seq_len: int = 128,\n",
    "        min_distance: int = 10,\n",
    "        max_distance: int = 100,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.marker_token = marker_token\n",
    "        self.cue_token = cue_token\n",
    "        self.seq_len = seq_len\n",
    "        self.min_distance = min_distance\n",
    "        self.max_distance = max_distance\n",
    "        \n",
    "    def generate_batch(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        device: str = 'cuda',\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Generate a batch of retrieval training examples.\n",
    "        \n",
    "        Returns:\n",
    "            input_ids: [B, seq_len]\n",
    "            targets: [B, seq_len] with -100 for non-target positions\n",
    "            needle_ids: [B] the values to retrieve\n",
    "        \"\"\"\n",
    "        # Random base sequence\n",
    "        input_ids = torch.randint(\n",
    "            0, self.vocab_size - 100, \n",
    "            (batch_size, self.seq_len), \n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Random needles\n",
    "        needle_ids = torch.randint(\n",
    "            1000, self.vocab_size - 100,\n",
    "            (batch_size,),\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Random positions for marker (early in sequence)\n",
    "        max_marker_pos = self.seq_len - self.max_distance - 2\n",
    "        min_marker_pos = 2\n",
    "        marker_positions = torch.randint(\n",
    "            min_marker_pos, max(min_marker_pos + 1, max_marker_pos),\n",
    "            (batch_size,),\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Place markers and needles\n",
    "        for b in range(batch_size):\n",
    "            mp = marker_positions[b].item()\n",
    "            input_ids[b, mp] = self.marker_token\n",
    "            input_ids[b, mp + 1] = needle_ids[b]\n",
    "        \n",
    "        # Place CUE at position -2\n",
    "        input_ids[:, -2] = self.cue_token\n",
    "        \n",
    "        # Targets: only position -1 matters (predict needle after CUE)\n",
    "        targets = torch.full(\n",
    "            (batch_size, self.seq_len), \n",
    "            -100,  # Ignore index\n",
    "            device=device\n",
    "        )\n",
    "        targets[:, -1] = needle_ids\n",
    "        \n",
    "        return input_ids, targets, needle_ids\n",
    "    \n",
    "    def generate_varied_batch(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        device: str = 'cuda',\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Generate batch with varied distances for curriculum learning.\n",
    "        \n",
    "        Some examples have short distance (easy), some have long (hard).\n",
    "        \"\"\"\n",
    "        input_ids = torch.randint(\n",
    "            0, self.vocab_size - 100,\n",
    "            (batch_size, self.seq_len),\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        needle_ids = torch.randint(\n",
    "            1000, self.vocab_size - 100,\n",
    "            (batch_size,),\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        targets = torch.full(\n",
    "            (batch_size, self.seq_len),\n",
    "            -100,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            # Varied distance: some easy (10-20), some hard (50-100)\n",
    "            if b < batch_size // 2:\n",
    "                # Easy: short distance\n",
    "                distance = torch.randint(self.min_distance, 30, (1,)).item()\n",
    "            else:\n",
    "                # Hard: longer distance  \n",
    "                distance = torch.randint(30, min(self.max_distance, self.seq_len - 5), (1,)).item()\n",
    "            \n",
    "            marker_pos = self.seq_len - distance - 3\n",
    "            marker_pos = max(2, marker_pos)\n",
    "            \n",
    "            input_ids[b, marker_pos] = self.marker_token\n",
    "            input_ids[b, marker_pos + 1] = needle_ids[b]\n",
    "            input_ids[b, -2] = self.cue_token\n",
    "            targets[b, -1] = needle_ids[b]\n",
    "        \n",
    "        return input_ids, targets, needle_ids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8bf22132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PART 3: MIXED TRAINING LOOP\n",
    "# =============================================================================\n",
    "\n",
    "def train_mixed(\n",
    "    model,\n",
    "    lm_data_loader,\n",
    "    steps: int = 10000,\n",
    "    lr: float = 3e-4,\n",
    "    warmup_steps: int = 1000,\n",
    "    retrieval_ratio: float = 0.1,  # 10% retrieval tasks\n",
    "    log_every: int = 100,\n",
    "    niah_every: int = 500,\n",
    "    device: str = 'cuda',\n",
    "):\n",
    "    \"\"\"\n",
    "    Training loop with mixed LM + retrieval objectives.\n",
    "    \n",
    "    Args:\n",
    "        retrieval_ratio: Fraction of batches that are retrieval tasks\n",
    "    \"\"\"\n",
    "    from torch.optim import AdamW\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "    \n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=steps, eta_min=lr * 0.01)\n",
    "    \n",
    "    # Retrieval data generator\n",
    "    retrieval_gen = RetrievalDataGenerator(\n",
    "        vocab_size=model.cfg.vocab_size,\n",
    "        seq_len=128,  # Match your typical seq_len\n",
    "    )\n",
    "    \n",
    "    lm_iter = iter(lm_data_loader)\n",
    "    history = {\n",
    "        'lm_loss': [],\n",
    "        'ret_loss': [],\n",
    "        'niah': [],\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # Warmup\n",
    "        if step < warmup_steps:\n",
    "            lr_scale = (step + 1) / warmup_steps\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg['lr'] = lr * lr_scale\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Decide: LM or Retrieval batch?\n",
    "        if torch.rand(1).item() < retrieval_ratio:\n",
    "            # Retrieval task\n",
    "            input_ids, targets, needles = retrieval_gen.generate_varied_batch(\n",
    "                batch_size=16,\n",
    "                device=device,\n",
    "            )\n",
    "            logits, _, diags, _ = model(input_ids, return_diagnostics=True)\n",
    "            \n",
    "            # Loss only on retrieval position\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)),\n",
    "                targets.view(-1),\n",
    "                ignore_index=-100\n",
    "            )\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            history['ret_loss'].append(loss.item())\n",
    "            batch_type = 'RET'\n",
    "            \n",
    "        else:\n",
    "            # LM task\n",
    "            try:\n",
    "                batch = next(lm_iter)\n",
    "            except StopIteration:\n",
    "                lm_iter = iter(lm_data_loader)\n",
    "                batch = next(lm_iter)\n",
    "            \n",
    "            input_ids = batch[:, :-1].to(device)\n",
    "            targets = batch[:, 1:].to(device)\n",
    "            \n",
    "            logits, loss, diags, _ = model(input_ids, targets, return_diagnostics=True)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            history['lm_loss'].append(loss.item())\n",
    "            batch_type = 'LM'\n",
    "        \n",
    "        if step >= warmup_steps:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Logging\n",
    "        if step % log_every == 0:\n",
    "            lm_avg = sum(history['lm_loss'][-100:]) / max(1, len(history['lm_loss'][-100:]))\n",
    "            ret_avg = sum(history['ret_loss'][-100:]) / max(1, len(history['ret_loss'][-100:]))\n",
    "            \n",
    "            # Get diagnostics\n",
    "            beta = diags[0].get('beta_mean', 0) if diags else 0\n",
    "            g = diags[0].get('g_mean', 0) if diags else 0\n",
    "            gate = diags[1].get('gate_mean', 0) if diags and len(diags) > 1 else 0\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            print(f\"[{step:5d}] LM={lm_avg:.3f} RET={ret_avg:.3f} | \"\n",
    "                  f\"β={beta:.3f} g={g:.3f} gate={gate:.2f} | \"\n",
    "                  f\"{elapsed/60:.1f}min\")\n",
    "        \n",
    "        # NIAH check (with proper cue)\n",
    "        if step % niah_every == 0 and step > 0:\n",
    "            model.eval()\n",
    "            niah_result = proper_niah_test(model, seq_len=128, needle_pos=32, n_trials=20)\n",
    "            history['niah'].append(niah_result['avg_ratio'])\n",
    "            model.train()\n",
    "    \n",
    "    print(f\"\\nTraining complete in {(time.time() - start_time)/60:.1f} min\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a0d42d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RETRIEVAL TRAINING + TESTING LOADED\n",
      "============================================================\n",
      "\n",
      "USAGE:\n",
      "\n",
      "1. Test current model with proper cue:\n",
      "   proper_niah_test(model, seq_len=128, needle_pos=32)\n",
      "\n",
      "2. Test at multiple distances:\n",
      "   test_niah_by_distance(model)\n",
      "\n",
      "3. Train with mixed LM + retrieval:\n",
      "   history = train_mixed(model, data_loader, steps=10000, retrieval_ratio=0.1)\n",
      "\n",
      "Special tokens used:\n",
      "  - MARKER (50251): Marks the needle for storage\n",
      "  - CUE (50250): Signals \"retrieve the marked value\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART 4: DIAGNOSTIC - TEST AT MULTIPLE DISTANCES\n",
    "# =============================================================================\n",
    "\n",
    "def test_niah_by_distance(\n",
    "    model,\n",
    "    distances: List[int] = [5, 10, 20, 40, 60, 80, 95],\n",
    "    n_trials: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Test NIAH at increasing distances to find capacity limit.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    print(\"\\nNIAH by distance (with cue):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    results = []\n",
    "    seq_len = 128\n",
    "    \n",
    "    for dist in distances:\n",
    "        needle_pos = seq_len - dist - 2  # Leave room for CUE and target\n",
    "        needle_pos = max(2, needle_pos)  # Ensure valid position\n",
    "        \n",
    "        result = proper_niah_test(\n",
    "            model, \n",
    "            seq_len=seq_len, \n",
    "            needle_pos=needle_pos, \n",
    "            n_trials=n_trials\n",
    "        )\n",
    "        results.append({\n",
    "            'distance': dist,\n",
    "            'needle_pos': needle_pos,\n",
    "            **result\n",
    "        })\n",
    "        print(f\"  Distance {dist:3d}: {result['avg_ratio']:.3f}x | \"\n",
    "              f\"rank={result['avg_rank']:.0f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RETRIEVAL TRAINING + TESTING LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "USAGE:\n",
    "\n",
    "1. Test current model with proper cue:\n",
    "   proper_niah_test(model, seq_len=128, needle_pos=32)\n",
    "\n",
    "2. Test at multiple distances:\n",
    "   test_niah_by_distance(model)\n",
    "\n",
    "3. Train with mixed LM + retrieval:\n",
    "   history = train_mixed(model, data_loader, steps=10000, retrieval_ratio=0.1)\n",
    "\n",
    "Special tokens used:\n",
    "  - MARKER (50251): Marks the needle for storage\n",
    "  - CUE (50250): Signals \"retrieve the marked value\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0fd1b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 20000 steps\n",
      "============================================================\n",
      "[    0] loss=10.875 lr=1.50e-07 | β=0.130 g=0.498 gate=0.50 | 2,005 tok/s\n",
      "[  100] loss=10.875 lr=1.51e-05 | β=0.129 g=0.504 gate=0.50 | 20,419 tok/s\n",
      "[  200] loss=10.814 lr=3.01e-05 | β=0.132 g=0.498 gate=0.50 | 23,121 tok/s\n",
      "[  300] loss=10.512 lr=4.51e-05 | β=0.132 g=0.500 gate=0.50 | 24,120 tok/s\n",
      "[  400] loss=9.822 lr=6.01e-05 | β=0.134 g=0.498 gate=0.49 | 24,452 tok/s\n",
      "NIAH: 0.6173x random (FAIL)\n",
      "[  500] loss=8.828 lr=7.51e-05 | β=0.133 g=0.496 gate=0.47 | 24,302 tok/s\n",
      "[  600] loss=7.907 lr=9.01e-05 | β=0.140 g=0.494 gate=0.48 | 24,684 tok/s\n",
      "[  700] loss=7.686 lr=1.05e-04 | β=0.144 g=0.496 gate=0.60 | 24,910 tok/s\n",
      "[  800] loss=7.553 lr=1.20e-04 | β=0.146 g=0.492 gate=0.65 | 24,711 tok/s\n",
      "[  900] loss=7.429 lr=1.35e-04 | β=0.144 g=0.494 gate=0.66 | 24,795 tok/s\n",
      "NIAH: 0.7525x random (FAIL)\n",
      "[ 1000] loss=7.408 lr=1.50e-04 | β=0.144 g=0.496 gate=0.66 | 24,206 tok/s\n",
      "[ 1100] loss=7.333 lr=1.65e-04 | β=0.139 g=0.494 gate=0.67 | 23,781 tok/s\n",
      "[ 1200] loss=7.227 lr=1.80e-04 | β=0.134 g=0.508 gate=0.66 | 23,230 tok/s\n",
      "[ 1300] loss=7.210 lr=1.95e-04 | β=0.140 g=0.500 gate=0.66 | 22,905 tok/s\n",
      "[ 1400] loss=7.209 lr=2.10e-04 | β=0.127 g=0.520 gate=0.68 | 22,610 tok/s\n",
      "NIAH: 0.3076x random (FAIL)\n",
      "[ 1500] loss=7.046 lr=2.25e-04 | β=0.134 g=0.504 gate=0.68 | 22,431 tok/s\n",
      "[ 1600] loss=7.079 lr=2.40e-04 | β=0.126 g=0.516 gate=0.70 | 22,331 tok/s\n",
      "[ 1700] loss=7.069 lr=2.55e-04 | β=0.129 g=0.512 gate=0.68 | 22,215 tok/s\n",
      "[ 1800] loss=7.012 lr=2.70e-04 | β=0.129 g=0.516 gate=0.68 | 22,251 tok/s\n",
      "[ 1900] loss=7.007 lr=2.85e-04 | β=0.129 g=0.508 gate=0.67 | 22,432 tok/s\n",
      "NIAH: 0.0696x random (FAIL)\n",
      "[ 2000] loss=6.958 lr=3.00e-04 | β=0.128 g=0.508 gate=0.67 | 22,527 tok/s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# CELL 10: Training\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m history = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mniah_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mniah_seq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mniah_needle_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 116\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, data_loader, steps, lr, warmup_steps, log_every, niah_every, niah_seq_len, niah_needle_pos)\u001b[39m\n\u001b[32m    113\u001b[39m opt.step()\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Track\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m].append(\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    117\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m].append(current_lr)\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Extract diagnostics\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: Training\n",
    "# =============================================================================\n",
    "\n",
    "history = train(\n",
    "    model,\n",
    "    data_loader,\n",
    "    steps=20000,\n",
    "    lr=3e-4,\n",
    "    warmup_steps=2000,\n",
    "    log_every=100,\n",
    "    niah_every=500,\n",
    "    niah_seq_len=128,\n",
    "    niah_needle_pos=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: POST-TRAINING DIAGNOSTICS\n",
    "# =============================================================================\n",
    "# This is the critical cell. Run after training to identify the failure mode.\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# POST-TRAINING DIAGNOSTIC ANALYSIS\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "# Final NIAH at multiple positions\n",
    "print(\"\\nNIAH at different needle positions:\")\n",
    "model.eval()\n",
    "for needle_pos in [16, 32, 64, 96]:\n",
    "    niah = simple_niah(model, seq_len=128, needle_pos=needle_pos, n_trials=30)\n",
    "    avg = sum(r['ratio'] for r in niah) / len(niah)\n",
    "    print(f\"  needle@{needle_pos}: {avg:.2f}x random\")\n",
    "\n",
    "# Full diagnostic suite\n",
    "post_diag = run_full_diagnostic(model, seq_len=128, needle_pos=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72722a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: Compare Pre vs Post Training\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRE vs POST TRAINING COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# GDN State Storage\n",
    "pre_snr = pre_diag['probe1_gdn_state']['summary'].get('max_snr', 0)\n",
    "post_snr = post_diag['probe1_gdn_state']['summary'].get('max_snr', 0)\n",
    "print(f\"\\nGDN State SNR:\")\n",
    "print(f\"  Pre:  {pre_snr:.4f}\")\n",
    "print(f\"  Post: {post_snr:.4f}\")\n",
    "print(f\"  Change: {post_snr - pre_snr:+.4f}\")\n",
    "\n",
    "# SWA Attention Focus\n",
    "pre_focus = pre_diag['probe2_swa_attention']['summary'].get('avg_focus_ratio', 0)\n",
    "post_focus = post_diag['probe2_swa_attention']['summary'].get('avg_focus_ratio', 0)\n",
    "print(f\"\\nSWA Focus Ratio:\")\n",
    "print(f\"  Pre:  {pre_focus:.4f}\")\n",
    "print(f\"  Post: {post_focus:.4f}\")\n",
    "print(f\"  Change: {post_focus - pre_focus:+.4f}\")\n",
    "\n",
    "# Gate Usage\n",
    "pre_gate = pre_diag['probe2_swa_attention']['summary'].get('avg_gate', 0.5)\n",
    "post_gate = post_diag['probe2_swa_attention']['summary'].get('avg_gate', 0.5)\n",
    "print(f\"\\nSWA Gate (global usage):\")\n",
    "print(f\"  Pre:  {pre_gate:.4f}\")\n",
    "print(f\"  Post: {post_gate:.4f}\")\n",
    "print(f\"  Change: {post_gate - pre_gate:+.4f}\")\n",
    "\n",
    "# Pipeline\n",
    "pre_delta = pre_diag['probe3_pipeline']['summary'].get('total_delta', 0)\n",
    "post_delta = post_diag['probe3_pipeline']['summary'].get('total_delta', 0)\n",
    "print(f\"\\nPipeline Similarity Delta:\")\n",
    "print(f\"  Pre:  {pre_delta:+.4f}\")\n",
    "print(f\"  Post: {post_delta:+.4f}\")\n",
    "print(f\"  Change: {post_delta - pre_delta:+.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
