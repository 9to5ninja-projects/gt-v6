{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triton Delta Rule Kernel\n",
    "\n",
    "**Target:** RTX 4050, PyTorch 2.10.0, Triton 3.6.0, CUDA 12.x\n",
    "\n",
    "**Fix:** Triton doesn't support `tensor[i,j] = x`. Must use vectorized block operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.11.0.dev20260128+cu128\n",
      "CUDA: 12.8\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Triton: 3.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "import triton\n",
    "print(f\"Triton: {triton.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton kernel loaded.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import time\n",
    "\n",
    "# =============================================================================\n",
    "# TRITON KERNEL - PROPER VECTORIZED OPERATIONS\n",
    "# =============================================================================\n",
    "\n",
    "@triton.jit\n",
    "def delta_rule_fwd_kernel(\n",
    "    K_ptr, V_ptr, Beta_ptr, G_ptr, State_ptr, Out_ptr,\n",
    "    stride_k_b, stride_k_t, stride_k_h, stride_k_d,\n",
    "    stride_v_b, stride_v_t, stride_v_h, stride_v_d,\n",
    "    stride_bg_b, stride_bg_t, stride_bg_h,\n",
    "    stride_s_b, stride_s_h, stride_s_k, stride_s_v,\n",
    "    stride_o_b, stride_o_t, stride_o_h, stride_o_v,\n",
    "    T,\n",
    "    K_DIM: tl.constexpr,\n",
    "    V_DIM: tl.constexpr,\n",
    "):\n",
    "    \"\"\"\n",
    "    Delta Rule: S = g*S + β*(v - S@k)⊗k\n",
    "    \n",
    "    One program per (batch, head). Sequential over T, vectorized over K×V.\n",
    "    \"\"\"\n",
    "    pid_b = tl.program_id(0)\n",
    "    pid_h = tl.program_id(1)\n",
    "    \n",
    "    # Offset vectors for block operations\n",
    "    k_offs = tl.arange(0, K_DIM)\n",
    "    v_offs = tl.arange(0, V_DIM)\n",
    "    \n",
    "    # State pointers [K_DIM, V_DIM]\n",
    "    state_base = State_ptr + pid_b * stride_s_b + pid_h * stride_s_h\n",
    "    state_ptrs = state_base + k_offs[:, None] * stride_s_k + v_offs[None, :] * stride_s_v\n",
    "    \n",
    "    # Load initial state\n",
    "    state = tl.load(state_ptrs).to(tl.float32)\n",
    "    \n",
    "    for t in range(T):\n",
    "        # Load k[t] [K_DIM]\n",
    "        k_base = K_ptr + pid_b * stride_k_b + t * stride_k_t + pid_h * stride_k_h\n",
    "        k_t = tl.load(k_base + k_offs * stride_k_d).to(tl.float32)\n",
    "        \n",
    "        # Load v[t] [V_DIM]\n",
    "        v_base = V_ptr + pid_b * stride_v_b + t * stride_v_t + pid_h * stride_v_h\n",
    "        v_t = tl.load(v_base + v_offs * stride_v_d).to(tl.float32)\n",
    "        \n",
    "        # Load scalars\n",
    "        bg_offset = pid_b * stride_bg_b + t * stride_bg_t + pid_h * stride_bg_h\n",
    "        beta_t = tl.load(Beta_ptr + bg_offset).to(tl.float32)\n",
    "        g_t = tl.load(G_ptr + bg_offset).to(tl.float32)\n",
    "        \n",
    "        # Prediction: sum_k state[k,v] * k_t[k]\n",
    "        pred = tl.sum(state * k_t[:, None], axis=0)  # [V_DIM]\n",
    "        \n",
    "        # Error\n",
    "        error = v_t - pred\n",
    "        \n",
    "        # Outer product\n",
    "        outer = k_t[:, None] * error[None, :]  # [K_DIM, V_DIM]\n",
    "        \n",
    "        # Update state\n",
    "        state = g_t * state + beta_t * outer\n",
    "        \n",
    "        # Output\n",
    "        out_t = tl.sum(state * k_t[:, None], axis=0)\n",
    "        \n",
    "        # Store output\n",
    "        out_base = Out_ptr + pid_b * stride_o_b + t * stride_o_t + pid_h * stride_o_h\n",
    "        tl.store(out_base + v_offs * stride_o_v, out_t)\n",
    "    \n",
    "    # Store final state\n",
    "    tl.store(state_ptrs, state)\n",
    "\n",
    "\n",
    "def triton_delta_rule(k, v, beta, g, initial_state=None):\n",
    "    B, T, H, K_DIM = k.shape\n",
    "    V_DIM = v.shape[-1]\n",
    "    device = k.device\n",
    "    orig_dtype = k.dtype\n",
    "    \n",
    "    k = k.contiguous().float()\n",
    "    v = v.contiguous().float()\n",
    "    beta = beta.contiguous().float()\n",
    "    g = g.contiguous().float()\n",
    "    \n",
    "    if initial_state is None:\n",
    "        state = torch.zeros(B, H, K_DIM, V_DIM, device=device, dtype=torch.float32)\n",
    "    else:\n",
    "        state = initial_state.contiguous().float().clone()\n",
    "    \n",
    "    out = torch.empty(B, T, H, V_DIM, device=device, dtype=torch.float32)\n",
    "    \n",
    "    grid = (B, H)\n",
    "    delta_rule_fwd_kernel[grid](\n",
    "        k, v, beta, g, state, out,\n",
    "        k.stride(0), k.stride(1), k.stride(2), k.stride(3),\n",
    "        v.stride(0), v.stride(1), v.stride(2), v.stride(3),\n",
    "        beta.stride(0), beta.stride(1), beta.stride(2),\n",
    "        state.stride(0), state.stride(1), state.stride(2), state.stride(3),\n",
    "        out.stride(0), out.stride(1), out.stride(2), out.stride(3),\n",
    "        T, K_DIM, V_DIM,\n",
    "    )\n",
    "    \n",
    "    return out.to(orig_dtype), state.to(orig_dtype)\n",
    "\n",
    "print(\"Triton kernel loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference implementation loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# REFERENCE (PyTorch sequential)\n",
    "# =============================================================================\n",
    "\n",
    "def sequential_delta_rule(k, v, beta, g, initial_state=None):\n",
    "    B, T, H, K = k.shape\n",
    "    V = v.shape[-1]\n",
    "    device, dtype = k.device, k.dtype\n",
    "    \n",
    "    state = torch.zeros(B, H, K, V, device=device, dtype=dtype) if initial_state is None else initial_state.clone()\n",
    "    \n",
    "    outputs = []\n",
    "    for t in range(T):\n",
    "        k_t, v_t = k[:, t], v[:, t]\n",
    "        beta_t, g_t = beta[:, t], g[:, t]\n",
    "        \n",
    "        pred = torch.einsum('bhkv,bhk->bhv', state, k_t)\n",
    "        error = v_t - pred\n",
    "        update = torch.einsum('bhv,bhk->bhkv', error, k_t)\n",
    "        state = g_t[..., None, None] * state + beta_t[..., None, None] * update\n",
    "        outputs.append(torch.einsum('bhkv,bhk->bhv', state, k_t))\n",
    "    \n",
    "    return torch.stack(outputs, dim=1), state\n",
    "\n",
    "print(\"Reference implementation loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CORRECTNESS TEST\n",
      "============================================================\n",
      "Output error:  0.00000007\n",
      "State error:   0.00000008\n",
      "→ ✓ PASS\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST CORRECTNESS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CORRECTNESS TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "B, T, H, K, V = 2, 64, 4, 32, 64\n",
    "\n",
    "k = F.normalize(torch.randn(B, T, H, K, device='cuda'), dim=-1)\n",
    "v = torch.randn(B, T, H, V, device='cuda')\n",
    "beta = torch.sigmoid(torch.randn(B, T, H, device='cuda') - 2)\n",
    "g = torch.sigmoid(torch.randn(B, T, H, device='cuda') + 2)\n",
    "\n",
    "out_ref, state_ref = sequential_delta_rule(k, v, beta, g)\n",
    "out_tri, state_tri = triton_delta_rule(k, v, beta, g)\n",
    "\n",
    "out_err = (out_tri.float() - out_ref.float()).norm() / out_ref.float().norm()\n",
    "state_err = (state_tri.float() - state_ref.float()).norm() / state_ref.float().norm()\n",
    "\n",
    "print(f\"Output error:  {out_err.item():.8f}\")\n",
    "print(f\"State error:   {state_err.item():.8f}\")\n",
    "print(f\"→ {'✓ PASS' if out_err < 1e-4 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SPEED BENCHMARK\n",
      "============================================================\n",
      "                   Config |    PyTorch |     Triton |  Speedup\n",
      "------------------------------------------------------------\n",
      "B=4,T=64,H=8:>25 |    15.40ms |     0.10ms |  154.17x\n",
      "B=8,T=128,H=8:>25 |    27.40ms |     0.28ms |   98.48x\n",
      "B=8,T=256,H=8:>25 |    62.21ms |     0.53ms |  116.52x\n",
      "B=16,T=128,H=8:>25 |    29.33ms |     0.48ms |   61.56x\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SPEED BENCHMARK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SPEED BENCHMARK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "configs = [\n",
    "    (4, 64, 8, 32, 64),\n",
    "    (8, 128, 8, 32, 64),\n",
    "    (8, 256, 8, 32, 64),\n",
    "    (16, 128, 8, 32, 64),\n",
    "]\n",
    "\n",
    "n_warmup, n_runs = 5, 20\n",
    "\n",
    "print(f\"{'Config':>25} | {'PyTorch':>10} | {'Triton':>10} | {'Speedup':>8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for B, T, H, K, V in configs:\n",
    "    k = F.normalize(torch.randn(B, T, H, K, device='cuda'), dim=-1)\n",
    "    v = torch.randn(B, T, H, V, device='cuda')\n",
    "    beta = torch.sigmoid(torch.randn(B, T, H, device='cuda') - 2)\n",
    "    g = torch.sigmoid(torch.randn(B, T, H, device='cuda') + 2)\n",
    "    \n",
    "    # PyTorch\n",
    "    for _ in range(n_warmup):\n",
    "        sequential_delta_rule(k, v, beta, g)\n",
    "        torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(n_runs):\n",
    "        sequential_delta_rule(k, v, beta, g)\n",
    "    torch.cuda.synchronize()\n",
    "    pytorch_ms = (time.perf_counter() - start) / n_runs * 1000\n",
    "    \n",
    "    # Triton\n",
    "    for _ in range(n_warmup):\n",
    "        triton_delta_rule(k, v, beta, g)\n",
    "        torch.cuda.synchronize()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(n_runs):\n",
    "        triton_delta_rule(k, v, beta, g)\n",
    "    torch.cuda.synchronize()\n",
    "    triton_ms = (time.perf_counter() - start) / n_runs * 1000\n",
    "    \n",
    "    speedup = pytorch_ms / triton_ms\n",
    "    print(f\"B={B},T={T},H={H}:>25 | {pytorch_ms:>8.2f}ms | {triton_ms:>8.2f}ms | {speedup:>7.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DELTA RULE VALIDATION\n",
      "============================================================\n",
      "Error1: 16.6302\n",
      "Error2: 0.00000227 (should be ~0)\n",
      "State growth: 1.000000x (should be ~1.0)\n",
      "→ ✓ PASS\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DELTA RULE VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DELTA RULE VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "B, H, K, V = 1, 4, 32, 64\n",
    "state = torch.zeros(B, H, K, V, device='cuda')\n",
    "k = F.normalize(torch.randn(B, H, K, device='cuda'), dim=-1)\n",
    "v = torch.randn(B, H, V, device='cuda')\n",
    "\n",
    "# First write\n",
    "pred1 = torch.einsum('bhkv,bhk->bhv', state, k)\n",
    "error1 = v - pred1\n",
    "state = state + torch.einsum('bhv,bhk->bhkv', error1, k)\n",
    "norm1 = state.norm().item()\n",
    "\n",
    "# Second write (SAME k, v)\n",
    "pred2 = torch.einsum('bhkv,bhk->bhv', state, k)\n",
    "error2 = v - pred2\n",
    "state = state + torch.einsum('bhv,bhk->bhkv', error2, k)\n",
    "norm2 = state.norm().item()\n",
    "\n",
    "print(f\"Error1: {error1.norm().item():.4f}\")\n",
    "print(f\"Error2: {error2.norm().item():.8f} (should be ~0)\")\n",
    "print(f\"State growth: {norm2/norm1:.6f}x (should be ~1.0)\")\n",
    "print(f\"→ {'✓ PASS' if error2.norm().item() < 1e-5 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDN test: torch.Size([2, 128, 256]) -> torch.Size([2, 128, 256]), state torch.Size([2, 8, 32, 64])\n",
      "✓ Integration successful\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INTEGRATION: GatedDeltaNetLayer\n",
    "# =============================================================================\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(x.pow(2).mean(-1, keepdim=True) + self.eps) * self.weight\n",
    "\n",
    "\n",
    "class GatedDeltaNetLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, head_dim, value_dim):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.value_dim = value_dim\n",
    "        \n",
    "        self.q_proj = nn.Linear(d_model, n_heads * head_dim, bias=False)\n",
    "        self.k_proj = nn.Linear(d_model, n_heads * head_dim, bias=False)\n",
    "        self.v_proj = nn.Linear(d_model, n_heads * value_dim, bias=False)\n",
    "        self.o_proj = nn.Linear(n_heads * value_dim, d_model, bias=False)\n",
    "        \n",
    "        self.beta_proj = nn.Linear(d_model, n_heads, bias=True)\n",
    "        nn.init.constant_(self.beta_proj.bias, -2.0)\n",
    "        \n",
    "        self.g_proj = nn.Linear(d_model, n_heads, bias=True)\n",
    "        nn.init.constant_(self.g_proj.bias, 2.0)\n",
    "        \n",
    "        self.norm = RMSNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, initial_state=None):\n",
    "        B, T, D = x.shape\n",
    "        H, K, V = self.n_heads, self.head_dim, self.value_dim\n",
    "        \n",
    "        x_norm = self.norm(x)\n",
    "        \n",
    "        k = self.k_proj(x_norm).view(B, T, H, K)\n",
    "        v = self.v_proj(x_norm).view(B, T, H, V)\n",
    "        k = F.normalize(k.float(), p=2, dim=-1).to(x.dtype)\n",
    "        \n",
    "        beta = torch.sigmoid(self.beta_proj(x_norm))\n",
    "        g = torch.sigmoid(self.g_proj(x_norm))\n",
    "        \n",
    "        out, state = triton_delta_rule(k, v, beta, g, initial_state)\n",
    "        \n",
    "        out = out.to(x.dtype).reshape(B, T, H * V)\n",
    "        return x + self.o_proj(out), state\n",
    "\n",
    "\n",
    "# Test\n",
    "layer = GatedDeltaNetLayer(256, 8, 32, 64).cuda()\n",
    "x = torch.randn(2, 128, 256, device='cuda')\n",
    "out, state = layer(x)\n",
    "print(f\"GDN test: {x.shape} -> {out.shape}, state {state.shape}\")\n",
    "print(\"✓ Integration successful\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
