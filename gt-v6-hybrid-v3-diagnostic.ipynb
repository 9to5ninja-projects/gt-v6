{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-md",
   "metadata": {},
   "source": [
    "# GroundThink v6 Hybrid Architecture\n",
    "## GDN + SWA with Diagnostic Instrumentation\n",
    "\n",
    "**Structure:**\n",
    "1. Configuration & Imports\n",
    "2. Core Components (RMSNorm, FFN)\n",
    "3. GatedDeltaNetLayer (GDN) - Recurrent memory\n",
    "4. SlidingWindowAttention (SWA) - Local + Global attention with state cross-attention\n",
    "5. TransparentHybrid - Main model\n",
    "6. **Diagnostic Toolkit** - Probe functions for debugging information flow\n",
    "7. Training Infrastructure\n",
    "8. Analysis & Execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-0-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 0: Configuration & Imports\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fla.ops.gated_delta_rule import chunk_gated_delta_rule\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Dict, Tuple, Literal, Any\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HybridConfig:\n",
    "    \"\"\"\n",
    "    Fully configurable hybrid architecture.\n",
    "    \n",
    "    Layer pattern examples:\n",
    "        'GS'      - 1 GDN, 1 SWA (minimal)\n",
    "        'GGSS'    - 2 GDN, 2 SWA\n",
    "        'GSGSG'   - Interleaved\n",
    "        'GGGSGGGS' - DeepSeek-style ratio\n",
    "    \"\"\"\n",
    "    # Model dimensions\n",
    "    d_model: int = 256\n",
    "    n_heads: int = 8\n",
    "    head_dim: int = 64          # Computed in __post_init__\n",
    "    expand_v: float = 2.0       # Value expansion for GDN state\n",
    "    vocab_size: int = 50257\n",
    "    \n",
    "    # Architecture\n",
    "    layer_pattern: str = \"GS\"\n",
    "    \n",
    "    # SWA config\n",
    "    window_size: int = 512\n",
    "    \n",
    "    # Initialization\n",
    "    init_std: float = 0.02\n",
    "    \n",
    "    # State accumulation strategy: 'replace', 'avg', 'weighted'\n",
    "    state_accumulation: str = 'weighted'\n",
    "    state_weight_new: float = 0.5  # Weight for newer state in weighted mode\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.head_dim = self.d_model // self.n_heads\n",
    "        self.value_dim = int(self.head_dim * self.expand_v)\n",
    "        \n",
    "    @property\n",
    "    def n_layers(self) -> int:\n",
    "        return len(self.layer_pattern)\n",
    "    \n",
    "    @property\n",
    "    def gdn_indices(self) -> List[int]:\n",
    "        return [i for i, t in enumerate(self.layer_pattern) if t == 'G']\n",
    "    \n",
    "    @property\n",
    "    def swa_indices(self) -> List[int]:\n",
    "        return [i for i, t in enumerate(self.layer_pattern) if t == 'S']\n",
    "    \n",
    "    def layer_type(self, idx: int) -> str:\n",
    "        return self.layer_pattern[idx]\n",
    "\n",
    "\n",
    "print(\"Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1-components",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Core Components\n",
    "# =============================================================================\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    \"\"\"Root Mean Square Layer Normalization.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        norm = x.float().pow(2).mean(-1, keepdim=True).add(self.eps).rsqrt()\n",
    "        return (x.float() * norm).type_as(x) * self.weight\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    \"\"\"SwiGLU Feed-Forward Network.\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: HybridConfig):\n",
    "        super().__init__()\n",
    "        hidden = int(cfg.d_model * 8 / 3)\n",
    "        hidden = ((hidden + 63) // 64) * 64  # Round to 64 for efficiency\n",
    "        \n",
    "        self.w1 = nn.Linear(cfg.d_model, hidden, bias=False)\n",
    "        self.w3 = nn.Linear(cfg.d_model, hidden, bias=False)\n",
    "        self.w2 = nn.Linear(hidden, cfg.d_model, bias=False)\n",
    "        self.norm = RMSNorm(cfg.d_model)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.norm(x)\n",
    "        return x + self.w2(F.silu(self.w1(h)) * self.w3(h))\n",
    "\n",
    "\n",
    "print(\"Core components loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2-gdn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Gated Delta Network Layer\n",
    "# =============================================================================\n",
    "\n",
    "class GatedDeltaNetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transparent GDN using raw FLA op.\n",
    "    \n",
    "    Delta Rule: Sₜ = αₜ * Sₜ₋₁ + βₜ * (vₜ ⊗ kₜ)\n",
    "    \n",
    "    Parameters:\n",
    "        αₜ (gate g): Controls forgetting (in log space for numerical stability)\n",
    "        βₜ (beta):   Controls write strength\n",
    "        Sₜ:          State matrix [B, H, K, V] - the associative memory\n",
    "    \n",
    "    Output: Sₜ @ qₜ (query the memory)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: HybridConfig, layer_idx: int):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.layer_idx = layer_idx\n",
    "        \n",
    "        H, K, V = cfg.n_heads, cfg.head_dim, cfg.value_dim\n",
    "        \n",
    "        # QKV projections\n",
    "        self.q_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.k_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.v_proj = nn.Linear(cfg.d_model, H * V, bias=False)\n",
    "        self.o_proj = nn.Linear(H * V, cfg.d_model, bias=False)\n",
    "        \n",
    "        # Gate projections (per-head scalars)\n",
    "        self.beta_proj = nn.Linear(cfg.d_model, H, bias=False)  # Write strength\n",
    "        self.g_proj = nn.Linear(cfg.d_model, H, bias=False)     # Forget gate (log space)\n",
    "        \n",
    "        self.norm = RMSNorm(cfg.d_model)\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        initial_state: Optional[torch.Tensor] = None,\n",
    "        output_state: bool = True\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor [B, T, D]\n",
    "            initial_state: Previous state [B, H, K, V] or None\n",
    "            output_state: Whether to return final state\n",
    "            \n",
    "        Returns:\n",
    "            output: [B, T, D]\n",
    "            state: [B, H, K, V] if output_state else None\n",
    "            diagnostics: Dict with internal values for inspection\n",
    "        \"\"\"\n",
    "        B, T, D = x.shape\n",
    "        H, K, V = self.cfg.n_heads, self.cfg.head_dim, self.cfg.value_dim\n",
    "        \n",
    "        # Pre-norm\n",
    "        x_norm = self.norm(x)\n",
    "        \n",
    "        # Project to Q, K, V\n",
    "        q = self.q_proj(x_norm).view(B, T, H, K)\n",
    "        k = self.k_proj(x_norm).view(B, T, H, K)\n",
    "        v = self.v_proj(x_norm).view(B, T, H, V)\n",
    "        \n",
    "        # Normalize K for stability (FLA convention)\n",
    "        k = F.normalize(k.float(), p=2, dim=-1).to(x.dtype)\n",
    "        \n",
    "        # Gates\n",
    "        beta = 0.5 + 0.5 *self.beta_proj(x_norm).sigmoid()   # [B, T, H] write strength ∈ (0,1)\n",
    "        g = F.logsigmoid(self.g_proj(x_norm))     # [B, T, H] forget gate in log space\n",
    "        \n",
    "        # Core delta rule operation\n",
    "        output, state = chunk_gated_delta_rule(\n",
    "            q, k, v, g, beta,\n",
    "            initial_state=initial_state,\n",
    "            output_final_state=output_state\n",
    "        )\n",
    "        \n",
    "        # Project back to model dimension\n",
    "        output = output.reshape(B, T, H * V)\n",
    "        output = self.o_proj(output)\n",
    "        \n",
    "        # Residual connection\n",
    "        output = x + output\n",
    "        \n",
    "        # Diagnostics\n",
    "        diagnostics = {\n",
    "            'beta_mean': beta.mean().item(),\n",
    "            'beta_std': beta.std().item(),\n",
    "            'beta_min': beta.min().item(),\n",
    "            'beta_max': beta.max().item(),\n",
    "            'g_mean': g.exp().mean().item(),      # Convert from log space\n",
    "            'g_std': g.exp().std().item(),\n",
    "            'state_norm': state.norm().item() if state is not None else 0,\n",
    "            'state_shape': tuple(state.shape) if state is not None else None,\n",
    "        }\n",
    "        \n",
    "        return output, state, diagnostics\n",
    "\n",
    "\n",
    "print(\"GatedDeltaNetLayer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3-swa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: SlidingWindowAttention with ALIGNED Retrieval\n",
    "# =============================================================================\n",
    "#\n",
    "# KEY INSIGHT: SWA must query in the same \"language\" GDN stores in.\n",
    "#\n",
    "# GDN stores with: State += β * (v ⊗ k) where k = k_proj(x)\n",
    "# GDN reads with:  output = State @ q\n",
    "#\n",
    "# For retrieval to work: query must align with stored keys.\n",
    "# \n",
    "# FIX: SWA uses GDN's k_proj for retrieval queries, and the same\n",
    "#      State @ q operation GDN uses internally.\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "class SlidingWindowAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    SWA with ALIGNED retrieval from GDN state.\n",
    "    \n",
    "    The retrieval pathway uses GDN's k_proj (passed during forward) to ensure\n",
    "    queries are in the same space as stored keys.\n",
    "    \n",
    "    Retrieval operation: State @ q (same as GDN's internal read)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: HybridConfig, layer_idx: int):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.layer_idx = layer_idx\n",
    "        H, K, V = cfg.n_heads, cfg.head_dim, cfg.value_dim\n",
    "        \n",
    "        # === LOCAL ATTENTION (unchanged) ===\n",
    "        self.q_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.k_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.v_proj = nn.Linear(cfg.d_model, H * K, bias=False)\n",
    "        self.o_proj = nn.Linear(H * K, cfg.d_model, bias=False)\n",
    "        \n",
    "        # === RETRIEVAL OUTPUT PROJECTION ===\n",
    "        # State @ q gives [B, H, T, V], need to project V -> d_model\n",
    "        self.retrieval_o_proj = nn.Linear(H * V, cfg.d_model, bias=False)\n",
    "        nn.init.xavier_uniform_(self.retrieval_o_proj.weight, gain=0.5)\n",
    "        \n",
    "        # === GATE: scales retrieval contribution ===\n",
    "        self.gate_proj = nn.Linear(cfg.d_model, H, bias=True)\n",
    "        nn.init.zeros_(self.gate_proj.weight)\n",
    "        nn.init.constant_(self.gate_proj.bias, 1.0)\n",
    "        \n",
    "        self.norm = RMSNorm(cfg.d_model)\n",
    "        self.scale = K ** -0.5\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor,\n",
    "        gdn_state: Optional[torch.Tensor] = None,\n",
    "        gdn_q_proj: Optional[nn.Module] = None,  # GDN's q_proj for aligned retrieval\n",
    "        return_attn: bool = False\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, Any], ...]:\n",
    "        B, T, D = x.shape\n",
    "        H = self.cfg.n_heads\n",
    "        K = self.cfg.head_dim\n",
    "        V = self.cfg.value_dim\n",
    "        W = self.cfg.window_size\n",
    "        \n",
    "        x_norm = self.norm(x)\n",
    "        \n",
    "        # === LOCAL ATTENTION ===\n",
    "        q = self.q_proj(x_norm).view(B, T, H, K).transpose(1, 2)\n",
    "        k_local = self.k_proj(x_norm).view(B, T, H, K).transpose(1, 2)\n",
    "        v_local = self.v_proj(x_norm).view(B, T, H, K).transpose(1, 2)\n",
    "        \n",
    "        mask = torch.ones(T, T, device=x.device, dtype=torch.bool)\n",
    "        mask = mask.triu(1) | mask.tril(-W - 1)\n",
    "        \n",
    "        attn_local = (q @ k_local.transpose(-2, -1)) * self.scale\n",
    "        attn_local = attn_local.masked_fill(mask.unsqueeze(0).unsqueeze(0), float('-inf'))\n",
    "        attn_weights_local = F.softmax(attn_local, dim=-1)\n",
    "        local_out = attn_weights_local @ v_local\n",
    "        \n",
    "        local_out = local_out.transpose(1, 2).reshape(B, T, H * K)\n",
    "        local_out = self.o_proj(local_out)\n",
    "        \n",
    "        # === ALIGNED RETRIEVAL FROM GDN STATE ===\n",
    "        retrieval_out = torch.zeros(B, T, D, device=x.device, dtype=x.dtype)\n",
    "        attn_weights_global = None\n",
    "        gate_values = torch.full((B, H, T, 1), 0.5, device=x.device, dtype=x.dtype)\n",
    "        \n",
    "        if gdn_state is not None:\n",
    "            state = gdn_state.to(x.dtype)  # [B, H, K, V]\n",
    "            \n",
    "            # === QUERY PROJECTION ===\n",
    "            if gdn_q_proj is not None:\n",
    "                # ALIGNED: Use GDN's q_proj for retrieval queries\n",
    "                # This matches how GDN internally queries its state\n",
    "                # k_proj defines storage address, q_proj defines retrieval query\n",
    "                q_ret = gdn_q_proj(x_norm)  # [B, T, H*K]\n",
    "            else:\n",
    "                # FALLBACK: Use local q_proj (for backwards compatibility)\n",
    "                q_ret = self.q_proj(x_norm)  # [B, T, H*K]\n",
    "            \n",
    "            q_ret = q_ret.view(B, T, H, K).transpose(1, 2)  # [B, H, T, K]\n",
    "            \n",
    "            # NOTE: GDN normalizes KEYS but not QUERIES\n",
    "            # For consistent behavior, we don't normalize q_ret here\n",
    "            # The dot product (q · k) works with normalized k and unnormalized q\n",
    "            \n",
    "            # === RETRIEVAL: Same operation GDN uses internally ===\n",
    "            # State @ q = Σᵢ vᵢ * (kᵢ · q)\n",
    "            # State: [B, H, K, V], q_ret: [B, H, T, K]\n",
    "            # Result: [B, H, T, V]\n",
    "            retrieved = torch.einsum('bhkv,bhtk->bhtv', state, q_ret)\n",
    "            \n",
    "            # Compute \"attention weights\" for diagnostics\n",
    "            # Approximated by q's alignment with state structure\n",
    "            state_k_norms = state.norm(dim=-1)  # [B, H, K]\n",
    "            attn_weights_global = torch.einsum('bhtk,bhk->bhtk', q_ret.abs(), state_k_norms)\n",
    "            attn_weights_global = F.softmax(attn_weights_global, dim=-1)  # [B, H, T, K]\n",
    "            \n",
    "            # Project retrieved values to output dimension\n",
    "            retrieved = retrieved.transpose(1, 2).reshape(B, T, H * V)\n",
    "            retrieval_out = self.retrieval_o_proj(retrieved)\n",
    "            \n",
    "            # Learned gate for retrieval scaling\n",
    "            gate_logits = self.gate_proj(x_norm)\n",
    "            gate = torch.sigmoid(gate_logits)\n",
    "            gate_values = gate.transpose(1, 2).unsqueeze(-1)\n",
    "            \n",
    "            gate_scale = gate.mean(dim=-1, keepdim=True)\n",
    "            retrieval_out = gate_scale * retrieval_out\n",
    "        \n",
    "        # === COMBINE: Local + Gated Retrieval ===\n",
    "        out = x + local_out + retrieval_out\n",
    "        \n",
    "        # Diagnostics\n",
    "        diagnostics = {\n",
    "            'local_attn_entropy': -(attn_weights_local * attn_weights_local.clamp(min=1e-8).log()).sum(-1).mean().item(),\n",
    "            'gate_mean': gate_values.mean().item(),\n",
    "            'gate_std': gate_values.std().item(),\n",
    "            'gate_min': gate_values.min().item(),\n",
    "            'gate_max': gate_values.max().item(),\n",
    "            'retrieval_norm': retrieval_out.norm().item(),\n",
    "            'local_norm': local_out.norm().item(),\n",
    "            'global_attn_entropy': (\n",
    "                -(attn_weights_global * attn_weights_global.clamp(min=1e-8).log()).sum(-1).mean().item() \n",
    "                if attn_weights_global is not None else 0\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        if return_attn:\n",
    "            return out, diagnostics, attn_weights_local, attn_weights_global, gate_values\n",
    "        return out, diagnostics\n",
    "\n",
    "\n",
    "print(\"SlidingWindowAttention loaded (ALIGNED RETRIEVAL via q_proj).\")\n",
    "print(\"  - Uses GDN's q_proj for retrieval queries (not k_proj)\")\n",
    "print(\"  - This matches how GDN internally retrieves from state\")\n",
    "print(\"  - Retrieval: q_proj(query) · k_proj(stored) -> correct interaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: TransparentHybrid Model (with aligned retrieval support)\n",
    "# =============================================================================\n",
    "#\n",
    "# CHANGE: SWA layers now receive gdn_k_proj for aligned retrieval\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "class TransparentHybrid(nn.Module):\n",
    "    \"\"\"\n",
    "    Configurable GDN + SWA hybrid with full visibility.\n",
    "    \n",
    "    Information flow:\n",
    "        - GDN layers compress sequence into state matrix Sₜ [H, K, V]\n",
    "        - State accumulates across GDN layers\n",
    "        - SWA layers query accumulated state for global context\n",
    "        - SWA uses GDN's k_proj for aligned retrieval (NEW)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: HybridConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Embedding\n",
    "        self.embed = nn.Embedding(cfg.vocab_size, cfg.d_model)\n",
    "        nn.init.normal_(self.embed.weight, std=cfg.init_std)\n",
    "        \n",
    "        # Build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.ffns = nn.ModuleList()\n",
    "        \n",
    "        for i, layer_type in enumerate(cfg.layer_pattern):\n",
    "            if layer_type == 'G':\n",
    "                self.layers.append(GatedDeltaNetLayer(cfg, i))\n",
    "            elif layer_type == 'S':\n",
    "                self.layers.append(SlidingWindowAttention(cfg, i))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {layer_type}\")\n",
    "            self.ffns.append(FFN(cfg))\n",
    "        \n",
    "        self.norm_f = RMSNorm(cfg.d_model)\n",
    "        self.lm_head = nn.Linear(cfg.d_model, cfg.vocab_size, bias=False)\n",
    "        self.lm_head.weight = self.embed.weight  # Tie weights\n",
    "        \n",
    "    def _accumulate_state(\n",
    "        self, \n",
    "        accumulated: Optional[torch.Tensor], \n",
    "        new_state: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Accumulate GDN states based on configured strategy.\"\"\"\n",
    "        if accumulated is None:\n",
    "            return new_state\n",
    "        \n",
    "        strategy = self.cfg.state_accumulation\n",
    "        if strategy == 'replace':\n",
    "            return new_state\n",
    "        elif strategy == 'avg':\n",
    "            return 0.5 * accumulated + 0.5 * new_state\n",
    "        elif strategy == 'weighted':\n",
    "            w = self.cfg.state_weight_new\n",
    "            return (1 - w) * accumulated + w * new_state\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown state accumulation strategy: {strategy}\")\n",
    "    \n",
    "    def _get_gdn_q_proj(self) -> Optional[nn.Module]:\n",
    "        \"\"\"Get the first GDN layer's q_proj for aligned retrieval.\n",
    "        \n",
    "        NOTE: We use q_proj (not k_proj) because:\n",
    "        - k_proj defines WHERE to store (storage address)\n",
    "        - q_proj defines WHAT to look for (retrieval query)\n",
    "        - GDN learns these to interact: retrieval = (q · k) * v\n",
    "        - SWA should query with q_proj to find what k_proj stored\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, GatedDeltaNetLayer):\n",
    "                return layer.q_proj\n",
    "        return None\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids: torch.Tensor, \n",
    "        targets: Optional[torch.Tensor] = None,\n",
    "        return_diagnostics: bool = False\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[List[Dict]], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Standard forward pass.\n",
    "        \n",
    "        Returns:\n",
    "            logits, loss, diagnostics (if requested), final_state\n",
    "        \"\"\"\n",
    "        x = self.embed(input_ids)\n",
    "        accumulated_state = None\n",
    "        all_diagnostics = []\n",
    "        \n",
    "        # Get GDN's q_proj for aligned SWA retrieval\n",
    "        gdn_q_proj = self._get_gdn_q_proj()\n",
    "        \n",
    "        for i, (layer, ffn) in enumerate(zip(self.layers, self.ffns)):\n",
    "            layer_type = self.cfg.layer_pattern[i]\n",
    "            \n",
    "            if layer_type == 'G':\n",
    "                x, state, diag = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "                accumulated_state = self._accumulate_state(accumulated_state, state)\n",
    "                diag['layer_type'] = 'GDN'\n",
    "            elif layer_type == 'S':\n",
    "                # Pass gdn_q_proj for aligned retrieval\n",
    "                x, diag = layer(x, gdn_state=accumulated_state, gdn_q_proj=gdn_q_proj)\n",
    "                diag['layer_type'] = 'SWA'\n",
    "            \n",
    "            x = ffn(x)\n",
    "            diag['layer_idx'] = i\n",
    "            all_diagnostics.append(diag)\n",
    "        \n",
    "        x = self.norm_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        \n",
    "        if return_diagnostics:\n",
    "            return logits, loss, all_diagnostics, accumulated_state\n",
    "        return logits, loss, None, accumulated_state\n",
    "\n",
    "\n",
    "print(\"TransparentHybrid loaded (with aligned retrieval support).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5-diagnostics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: DIAGNOSTIC TOOLKIT\n",
    "# =============================================================================\n",
    "# These functions probe the information flow to identify bottlenecks.\n",
    "# Run these AFTER training to understand why NIAH fails.\n",
    "#\n",
    "# Decision Tree:\n",
    "#   1. probe_gdn_state_content() -> Is the needle IN the GDN state?\n",
    "#      - Yes -> Architecture working, tune gate/fusion\n",
    "#      - No  -> Is it being written? Check beta values\n",
    "#               - No write -> Fix GDN write mechanism\n",
    "#               - Written but lost -> Fix SWA query mechanism\n",
    "#\n",
    "#   2. visualize_swa_state_attention() -> Is SWA attending to state?\n",
    "#      - Check attention entropy and head specialization\n",
    "#\n",
    "#   3. trace_needle_pipeline() -> End-to-end similarity tracking\n",
    "# =============================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def probe_gdn_state_content(\n",
    "    model: TransparentHybrid, \n",
    "    input_ids: torch.Tensor, \n",
    "    target_token_pos: int = 32,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Probe 1: Check if specific token information is encoded in GDN state.\n",
    "    \n",
    "    This directly tests the WRITE path: is the GDN storing token-specific\n",
    "    information that can be retrieved later?\n",
    "    \n",
    "    Args:\n",
    "        model: The hybrid model\n",
    "        input_ids: Input sequence [1, T] with a \"needle\" token at target_token_pos\n",
    "        target_token_pos: Position of the needle token to probe for\n",
    "        verbose: Print results\n",
    "        \n",
    "    Returns:\n",
    "        Dict with per-layer retrieval analysis and signal-to-noise ratios\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = {'layers': [], 'summary': {}}\n",
    "    \n",
    "    x = model.embed(input_ids)\n",
    "    accumulated_state = None\n",
    "    needle_id = input_ids[0, target_token_pos].item()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROBE 1: GDN State Content Analysis\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Needle token ID: {needle_id} at position {target_token_pos}\")\n",
    "        print()\n",
    "    \n",
    "    for i, (layer, ffn) in enumerate(zip(model.layers, model.ffns)):\n",
    "        layer_type = model.cfg.layer_pattern[i]\n",
    "        \n",
    "        if layer_type == 'G':\n",
    "            x, layer_state, diag = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "            accumulated_state = model._accumulate_state(accumulated_state, layer_state)\n",
    "            \n",
    "            # Get needle embedding and project through this layer's K projection\n",
    "            needle_embed = model.embed.weight[needle_id]\n",
    "            needle_key = layer.k_proj(needle_embed).view(model.cfg.n_heads, model.cfg.head_dim)\n",
    "            needle_key = F.normalize(needle_key.float(), p=2, dim=-1)\n",
    "            \n",
    "            # Query the state: how much of the needle is retrievable?\n",
    "            # needle_key @ state -> retrieved value\n",
    "            retrieved = torch.einsum('hk,bhkv->bhv', needle_key, layer_state.float())\n",
    "            needle_retrieval_norm = retrieved.norm().item()\n",
    "            \n",
    "            # Compare to random token baseline\n",
    "            rand_token = torch.randint(0, model.cfg.vocab_size, (1,), device=input_ids.device).item()\n",
    "            rand_embed = model.embed.weight[rand_token]\n",
    "            rand_key = layer.k_proj(rand_embed).view(model.cfg.n_heads, model.cfg.head_dim)\n",
    "            rand_key = F.normalize(rand_key.float(), p=2, dim=-1)\n",
    "            rand_retrieved = torch.einsum('hk,bhkv->bhv', rand_key, layer_state.float())\n",
    "            rand_retrieval_norm = rand_retrieved.norm().item()\n",
    "            \n",
    "            snr = needle_retrieval_norm / (rand_retrieval_norm + 1e-8)\n",
    "            \n",
    "            layer_result = {\n",
    "                'layer_idx': i,\n",
    "                'layer_type': 'GDN',\n",
    "                'state_norm': layer_state.norm().item(),\n",
    "                'state_shape': tuple(layer_state.shape),\n",
    "                'needle_retrieval_norm': needle_retrieval_norm,\n",
    "                'random_retrieval_norm': rand_retrieval_norm,\n",
    "                'signal_to_noise': snr,\n",
    "                'beta_mean': diag['beta_mean'],\n",
    "                'beta_std': diag['beta_std'],\n",
    "                'g_mean': diag['g_mean'],\n",
    "            }\n",
    "            results['layers'].append(layer_result)\n",
    "            \n",
    "            if verbose:\n",
    "                status = \"✓\" if snr > 1.0 else \"✗\"\n",
    "                print(f\"  [GDN Layer {i}] {status}\")\n",
    "                print(f\"      State: norm={layer_state.norm().item():.4f}, shape={tuple(layer_state.shape)}\")\n",
    "                print(f\"      Needle Retrieval: {needle_retrieval_norm:.6f}\")\n",
    "                print(f\"      Random Retrieval: {rand_retrieval_norm:.6f}\")\n",
    "                print(f\"      Signal-to-Noise:  {snr:.4f} {'(GOOD)' if snr > 1.0 else '(WEAK)'}\")\n",
    "                print(f\"      β={diag['beta_mean']:.3f}±{diag['beta_std']:.3f}, g={diag['g_mean']:.3f}\")\n",
    "                print()\n",
    "                \n",
    "        elif layer_type == 'S':\n",
    "            x, _ = layer(x, gdn_state=accumulated_state)\n",
    "            results['layers'].append({'layer_idx': i, 'layer_type': 'SWA'})\n",
    "        \n",
    "        x = ffn(x)\n",
    "    \n",
    "    # Summary\n",
    "    gdn_results = [r for r in results['layers'] if r['layer_type'] == 'GDN']\n",
    "    if gdn_results:\n",
    "        avg_snr = sum(r['signal_to_noise'] for r in gdn_results) / len(gdn_results)\n",
    "        max_snr = max(r['signal_to_noise'] for r in gdn_results)\n",
    "        results['summary'] = {\n",
    "            'avg_snr': avg_snr,\n",
    "            'max_snr': max_snr,\n",
    "            'needle_stored': max_snr > 1.0,\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Summary: avg_SNR={avg_snr:.4f}, max_SNR={max_snr:.4f}\")\n",
    "            if max_snr > 1.0:\n",
    "                print(f\"  → Needle IS stored in GDN state\")\n",
    "            else:\n",
    "                print(f\"  → Needle NOT effectively stored (check beta/write mechanism)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_swa_state_attention(\n",
    "    model: nn.Module,\n",
    "    input_ids: torch.Tensor,\n",
    "    target_swa_layer: Optional[int] = None,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Probe 2: Analyze SWA's attention to GDN state.\n",
    "    \n",
    "    UPDATED: Now passes gdn_k_proj for aligned retrieval.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # First pass to get GDN state\n",
    "    x = model.embed(input_ids)\n",
    "    accumulated_state = None\n",
    "    \n",
    "    # Get gdn_q_proj for aligned retrieval\n",
    "    gdn_q_proj = model._get_gdn_q_proj() if hasattr(model, '_get_gdn_q_proj') else None\n",
    "    \n",
    "    # Forward through layers to accumulate state\n",
    "    for i, (layer, ffn) in enumerate(zip(model.layers, model.ffns)):\n",
    "        layer_type = model.cfg.layer_pattern[i]\n",
    "        \n",
    "        if layer_type == 'G':\n",
    "            x, state, _ = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "            accumulated_state = model._accumulate_state(accumulated_state, state)\n",
    "        elif layer_type == 'S':\n",
    "            x, _ = layer(x, gdn_state=accumulated_state, gdn_q_proj=gdn_q_proj)\n",
    "        \n",
    "        x = ffn(x)\n",
    "    \n",
    "    # Now analyze each SWA layer's attention\n",
    "    results = {'layers': [], 'summary': {}}\n",
    "    \n",
    "    x = model.embed(input_ids)\n",
    "    accumulated_state = None\n",
    "    \n",
    "    for i, (layer, ffn) in enumerate(zip(model.layers, model.ffns)):\n",
    "        layer_type = model.cfg.layer_pattern[i]\n",
    "        \n",
    "        if layer_type == 'G':\n",
    "            x, state, _ = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "            accumulated_state = model._accumulate_state(accumulated_state, state)\n",
    "            x = ffn(x)\n",
    "            continue\n",
    "        \n",
    "        # SWA layer - get attention weights WITH aligned retrieval\n",
    "        if target_swa_layer is not None and i != target_swa_layer:\n",
    "            x, _ = layer(x, gdn_state=accumulated_state, gdn_q_proj=gdn_q_proj)\n",
    "            x = ffn(x)\n",
    "            continue\n",
    "        \n",
    "        # Get detailed attention for this SWA layer\n",
    "        out, diag, attn_local, attn_global, gate = layer(\n",
    "            x, \n",
    "            gdn_state=accumulated_state,\n",
    "            gdn_q_proj=gdn_q_proj,  # Pass for aligned retrieval\n",
    "            return_attn=True\n",
    "        )\n",
    "        \n",
    "        if attn_global is None:\n",
    "            x = ffn(out)\n",
    "            continue\n",
    "        \n",
    "        # Analyze global attention\n",
    "        # attn_global: [B, H, T, K] - attention over K state dimensions\n",
    "        H = attn_global.shape[1]\n",
    "        T = attn_global.shape[2]\n",
    "        K = attn_global.shape[3]\n",
    "        \n",
    "        # Focus on final token's attention to state\n",
    "        final_attn = attn_global[0, :, -1, :]  # [H, K]\n",
    "        \n",
    "        # Per-head analysis\n",
    "        head_analysis = []\n",
    "        for h in range(H):\n",
    "            attn_h = final_attn[h]  # [K]\n",
    "            entropy = -(attn_h * attn_h.clamp(min=1e-8).log()).sum().item()\n",
    "            max_attn, max_slot = attn_h.max(dim=0)\n",
    "            head_analysis.append({\n",
    "                'head': h,\n",
    "                'entropy': entropy,\n",
    "                'max_attn': max_attn.item(),\n",
    "                'max_slot': max_slot.item(),\n",
    "            })\n",
    "        \n",
    "        # Average entropy across heads\n",
    "        avg_entropy = sum(h['entropy'] for h in head_analysis) / H\n",
    "        max_entropy = math.log(K)  # Uniform distribution\n",
    "        focus_ratio = 1 - (avg_entropy / max_entropy)\n",
    "        \n",
    "        layer_result = {\n",
    "            'layer_idx': i,\n",
    "            'layer_type': 'SWA',\n",
    "            'local_attn_shape': tuple(attn_local.shape),\n",
    "            'global_attn_shape': tuple(attn_global.shape),\n",
    "            'gate_mean': gate.mean().item(),\n",
    "            'gate_std': gate.std().item(),\n",
    "            'avg_global_entropy': avg_entropy,\n",
    "            'max_possible_entropy': max_entropy,\n",
    "            'focus_ratio': focus_ratio,\n",
    "            'per_head': head_analysis,\n",
    "        }\n",
    "        results['layers'].append(layer_result)\n",
    "        \n",
    "        if verbose:\n",
    "            status = \"✓\" if focus_ratio > 0.2 else \"✗\"\n",
    "            print(f\"\\n  [SWA Layer {i}] {status}\")\n",
    "            print(f\"      Global Attn Shape: {tuple(attn_global.shape)}\")\n",
    "            print(f\"      Gate: mean={gate.mean().item():.3f}, std={gate.std().item():.3f}\")\n",
    "            print(f\"      Avg Entropy: {avg_entropy:.4f} / {max_entropy:.4f} (max)\")\n",
    "            focus_status = \"FOCUSED\" if focus_ratio > 0.2 else \"DIFFUSE\"\n",
    "            print(f\"      Focus Ratio: {focus_ratio:.4f} ({focus_status})\")\n",
    "            print(f\"      Per-head (final token -> state):\")\n",
    "            for h in head_analysis:\n",
    "                print(f\"        H{h['head']}: entropy={h['entropy']:.3f}, max={h['max_attn']:.3f}@slot{h['max_slot']}\")\n",
    "        \n",
    "        x = ffn(out)\n",
    "    \n",
    "    # Summary\n",
    "    if results['layers']:\n",
    "        avg_focus = sum(l['focus_ratio'] for l in results['layers']) / len(results['layers'])\n",
    "        avg_gate = sum(l['gate_mean'] for l in results['layers']) / len(results['layers'])\n",
    "        results['summary'] = {\n",
    "            'avg_focus_ratio': avg_focus,\n",
    "            'avg_gate': avg_gate,\n",
    "            'attention_focused': avg_focus > 0.2,\n",
    "            'using_global': avg_gate > 0.3,\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n  Summary: avg_focus={avg_focus:.4f}, avg_gate={avg_gate:.4f}\")\n",
    "            if avg_focus < 0.2:\n",
    "                print(\"  → SWA attention is DIFFUSE (not learning to query)\")\n",
    "            else:\n",
    "                print(\"  → SWA attention is FOCUSED (learning to query specific slots)\")\n",
    "            if avg_gate > 0.3:\n",
    "                print(\"  → SWA is USING global state (gate > 0.3)\")\n",
    "            else:\n",
    "                print(\"  → SWA is IGNORING global state (gate < 0.3)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "@torch.no_grad()\n",
    "def trace_needle_pipeline(\n",
    "    model: TransparentHybrid, \n",
    "    input_ids: torch.Tensor, \n",
    "    needle_pos: int = 32,\n",
    "    query_pos: int = -1,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Probe 3: Trace needle information through the entire forward pass.\n",
    "    \n",
    "    Tracks cosine similarity between the query position's representation\n",
    "    and the needle token's embedding as it evolves through layers.\n",
    "    \n",
    "    Look for:\n",
    "        - Similarity INCREASE at SWA layers (retrieval working)\n",
    "        - State containing needle at GDN layers\n",
    "    \n",
    "    Args:\n",
    "        model: The hybrid model\n",
    "        input_ids: Input sequence [1, T] with needle at needle_pos\n",
    "        needle_pos: Position of needle token\n",
    "        query_pos: Position to track (default: -1 = final position)\n",
    "        verbose: Print results\n",
    "        \n",
    "    Returns:\n",
    "        Dict with per-layer trajectory\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    T = input_ids.shape[1]\n",
    "    if query_pos < 0:\n",
    "        query_pos = T + query_pos  # Convert negative index\n",
    "    \n",
    "    needle_id = input_ids[0, needle_pos].item()\n",
    "    needle_embed = model.embed.weight[needle_id].float()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROBE 3: Needle Pipeline Trace\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Needle: token {needle_id} @ pos {needle_pos}\")\n",
    "        print(f\"Query:  pos {query_pos}\")\n",
    "        print(f\"Distance: {query_pos - needle_pos} tokens\\n\")\n",
    "    \n",
    "    x = model.embed(input_ids)\n",
    "    accumulated_state = None\n",
    "    trajectory = []\n",
    "    \n",
    "    # Initial similarity\n",
    "    init_rep = x[0, query_pos].float()\n",
    "    init_sim = F.cosine_similarity(init_rep, needle_embed, dim=0).item()\n",
    "    trajectory.append({\n",
    "        'stage': 'embed',\n",
    "        'layer_idx': -1,\n",
    "        'layer_type': 'EMBED',\n",
    "        'similarity': init_sim,\n",
    "        'delta': 0.0,\n",
    "    })\n",
    "    \n",
    "    for i, (layer, ffn) in enumerate(zip(model.layers, model.ffns)):\n",
    "        layer_type = model.cfg.layer_pattern[i]\n",
    "        \n",
    "        pre_rep = x[0, query_pos].float()\n",
    "        pre_sim = F.cosine_similarity(pre_rep, needle_embed, dim=0).item()\n",
    "        \n",
    "        state_needle_norm = None\n",
    "        \n",
    "        if layer_type == 'G':\n",
    "            x, layer_state, diag = layer(x, initial_state=accumulated_state, output_state=True)\n",
    "            accumulated_state = model._accumulate_state(accumulated_state, layer_state)\n",
    "            \n",
    "            # Check if needle is in state\n",
    "            needle_key = layer.k_proj(needle_embed.to(x.dtype)).view(model.cfg.n_heads, model.cfg.head_dim)\n",
    "            needle_key = F.normalize(needle_key.float(), p=2, dim=-1)\n",
    "            retrieved = torch.einsum('hk,bhkv->bhv', needle_key, layer_state.float())\n",
    "            state_needle_norm = retrieved.norm().item()\n",
    "            \n",
    "        elif layer_type == 'S':\n",
    "            x, diag = layer(x, gdn_state=accumulated_state)\n",
    "        \n",
    "        x = ffn(x)\n",
    "        \n",
    "        post_rep = x[0, query_pos].float()\n",
    "        post_sim = F.cosine_similarity(post_rep, needle_embed, dim=0).item()\n",
    "        delta = post_sim - pre_sim\n",
    "        \n",
    "        layer_result = {\n",
    "            'stage': f'layer_{i}',\n",
    "            'layer_idx': i,\n",
    "            'layer_type': layer_type,\n",
    "            'pre_sim': pre_sim,\n",
    "            'post_sim': post_sim,\n",
    "            'delta': delta,\n",
    "            'state_needle_norm': state_needle_norm,\n",
    "        }\n",
    "        trajectory.append(layer_result)\n",
    "        \n",
    "        if verbose:\n",
    "            arrow = \"↑\" if delta > 0.01 else (\"↓\" if delta < -0.01 else \"→\")\n",
    "            type_str = 'GDN' if layer_type == 'G' else 'SWA'\n",
    "            state_str = f\", state_needle={state_needle_norm:.4f}\" if state_needle_norm else \"\"\n",
    "            print(f\"  L{i:2d} [{type_str}]: {pre_sim:+.4f} {arrow} {post_sim:+.4f} (Δ{delta:+.4f}){state_str}\")\n",
    "    \n",
    "    # Summary\n",
    "    final_sim = trajectory[-1]['post_sim']\n",
    "    total_delta = final_sim - init_sim\n",
    "    \n",
    "    # Find where biggest gains/losses happen\n",
    "    max_gain = max(t['delta'] for t in trajectory[1:])\n",
    "    max_loss = min(t['delta'] for t in trajectory[1:])\n",
    "    max_gain_layer = [t for t in trajectory[1:] if t['delta'] == max_gain][0]\n",
    "    max_loss_layer = [t for t in trajectory[1:] if t['delta'] == max_loss][0]\n",
    "    \n",
    "    results = {\n",
    "        'trajectory': trajectory,\n",
    "        'summary': {\n",
    "            'initial_sim': init_sim,\n",
    "            'final_sim': final_sim,\n",
    "            'total_delta': total_delta,\n",
    "            'max_gain': max_gain,\n",
    "            'max_gain_layer': max_gain_layer['layer_idx'],\n",
    "            'max_gain_type': max_gain_layer['layer_type'],\n",
    "            'max_loss': max_loss,\n",
    "            'max_loss_layer': max_loss_layer['layer_idx'],\n",
    "            'retrieval_working': total_delta > 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n  Summary:\")\n",
    "        print(f\"    Initial → Final: {init_sim:+.4f} → {final_sim:+.4f} (Δ{total_delta:+.4f})\")\n",
    "        print(f\"    Max gain: {max_gain:+.4f} at L{max_gain_layer['layer_idx']} [{max_gain_layer['layer_type']}]\")\n",
    "        print(f\"    Max loss: {max_loss:+.4f} at L{max_loss_layer['layer_idx']} [{max_loss_layer['layer_type']}]\")\n",
    "        if total_delta > 0:\n",
    "            print(f\"    → Needle info IS reaching query position\")\n",
    "        else:\n",
    "            print(f\"    → Needle info NOT reaching query position\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_full_diagnostic(\n",
    "    model: TransparentHybrid,\n",
    "    seq_len: int = 128,\n",
    "    needle_pos: int = 32,\n",
    "    needle_token: int = 50000,\n",
    "    device: str = 'cuda'\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run all three diagnostic probes and return combined results.\n",
    "    \n",
    "    This is your one-stop diagnostic function. Run this after training\n",
    "    to understand where the information pipeline is breaking.\n",
    "    \"\"\"\n",
    "    # Create test sequence with needle\n",
    "    tokens = torch.randint(1000, 10000, (1, seq_len), device=device)\n",
    "    tokens[0, needle_pos] = needle_token\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*60)\n",
    "    print(\"# FULL DIAGNOSTIC SUITE\")\n",
    "    print(\"#\"*60)\n",
    "    print(f\"Sequence length: {seq_len}\")\n",
    "    print(f\"Needle token: {needle_token} @ position {needle_pos}\")\n",
    "    print(f\"Query position: {seq_len - 1} (final)\")\n",
    "    \n",
    "    # Run probes\n",
    "    probe1 = probe_gdn_state_content(model, tokens, target_token_pos=needle_pos)\n",
    "    probe2 = visualize_swa_state_attention(model, tokens)\n",
    "    probe3 = trace_needle_pipeline(model, tokens, needle_pos=needle_pos)\n",
    "    \n",
    "    # Diagnosis\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DIAGNOSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    needle_stored = probe1['summary'].get('needle_stored', False)\n",
    "    attention_focused = probe2['summary'].get('attention_focused', False)\n",
    "    using_global = probe2['summary'].get('using_global', False)\n",
    "    retrieval_working = probe3['summary'].get('retrieval_working', False)\n",
    "    \n",
    "    if needle_stored and attention_focused and retrieval_working:\n",
    "        print(\"✓ Architecture appears to be WORKING\")\n",
    "        print(\"  Focus on: Gate tuning, fusion weights, training dynamics\")\n",
    "    elif not needle_stored:\n",
    "        print(\"✗ Problem: GDN NOT storing needle\")\n",
    "        print(\"  → Check beta (write strength) values\")\n",
    "        print(\"  → Check beta_proj initialization\")\n",
    "        print(\"  → May need stronger write gate bias\")\n",
    "    elif needle_stored and not attention_focused:\n",
    "        print(\"✗ Problem: SWA attention is DIFFUSE\")\n",
    "        print(\"  → Needle is stored but SWA can't find it\")\n",
    "        print(\"  → Check state_k_proj / state_v_proj initialization\")\n",
    "        print(\"  → Consider attentional reading instead of additive fusion\")\n",
    "    elif needle_stored and attention_focused and not using_global:\n",
    "        print(\"✗ Problem: SWA IGNORING global state\")\n",
    "        print(\"  → Gate is too low\")\n",
    "        print(\"  → Consider initializing gate bias positive\")\n",
    "        print(\"  → Or switch to learned gating mechanism\")\n",
    "    else:\n",
    "        print(\"? Unclear failure mode - review individual probe results\")\n",
    "    \n",
    "    return {\n",
    "        'probe1_gdn_state': probe1,\n",
    "        'probe2_swa_attention': probe2,\n",
    "        'probe3_pipeline': probe3,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Diagnostic Toolkit loaded.\")\n",
    "print(\"  - probe_gdn_state_content()\")\n",
    "print(\"  - visualize_swa_state_attention()\")\n",
    "print(\"  - trace_needle_pipeline()\")\n",
    "print(\"  - run_full_diagnostic()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Training Infrastructure\n",
    "# =============================================================================\n",
    "\n",
    "def simple_niah(\n",
    "    model: TransparentHybrid, \n",
    "    seq_len: int = 128, \n",
    "    needle_pos: int = 32, \n",
    "    needle_token: int = 50000,\n",
    "    n_trials: int = 20\n",
    ") -> List[Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Needle-In-A-Haystack test.\n",
    "    \n",
    "    Insert a rare token early in sequence, check if model assigns\n",
    "    higher probability to it at the final position.\n",
    "    \n",
    "    Returns:\n",
    "        List of trial results with needle probability and ratio vs random\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_trials):\n",
    "            tokens = torch.randint(1000, 10000, (1, seq_len), device=next(model.parameters()).device)\n",
    "            tokens[0, needle_pos] = needle_token\n",
    "            \n",
    "            logits, _, _, state = model(tokens, return_diagnostics=True)\n",
    "            \n",
    "            final_probs = F.softmax(logits[0, -1].float(), dim=-1)\n",
    "            needle_prob = final_probs[needle_token].item()\n",
    "            random_baseline = 1.0 / model.cfg.vocab_size\n",
    "            \n",
    "            results.append({\n",
    "                'needle_prob': needle_prob,\n",
    "                'ratio': needle_prob / random_baseline,\n",
    "                'state_norm': state.norm().item() if state is not None else 0,\n",
    "            })\n",
    "    \n",
    "    avg_ratio = sum(r['ratio'] for r in results) / len(results)\n",
    "    print(f\"NIAH: {avg_ratio:.4f}x random ({'PASS' if avg_ratio > 1.0 else 'FAIL'})\")\n",
    "    return results\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Simple streaming data loader for training.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        token_tensor: torch.Tensor, \n",
    "        batch_size: int = 4, \n",
    "        seq_len: int = 128\n",
    "    ):\n",
    "        self.tokens = token_tensor\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def get_batch(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        ix = torch.randint(0, len(self.tokens) - self.seq_len - 1, (self.batch_size,))\n",
    "        x = torch.stack([self.tokens[i:i+self.seq_len] for i in ix])\n",
    "        y = torch.stack([self.tokens[i+1:i+self.seq_len+1] for i in ix])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: TransparentHybrid,\n",
    "    data_loader: DataLoader,\n",
    "    steps: int = 10000,\n",
    "    lr: float = 3e-4,\n",
    "    warmup_steps: int = 200,\n",
    "    log_every: int = 100,\n",
    "    niah_every: int = 500,\n",
    "    niah_seq_len: int = 128,\n",
    "    niah_needle_pos: int = 32,\n",
    ") -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Training loop with monitoring.\n",
    "    \n",
    "    Returns:\n",
    "        History dict with loss, NIAH ratios, and diagnostic values\n",
    "    \"\"\"\n",
    "    from torch.optim import AdamW\n",
    "    \n",
    "    opt = AdamW(model.parameters(), lr=lr, betas=(0.9, 0.95), weight_decay=0.1)\n",
    "    \n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    print(f\"\\nTraining {steps} steps\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # LR schedule: linear warmup then cosine decay\n",
    "        if step < warmup_steps:\n",
    "            current_lr = lr * (step + 1) / warmup_steps\n",
    "        else:\n",
    "            progress = (step - warmup_steps) / (steps - warmup_steps)\n",
    "            current_lr = lr * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "        for pg in opt.param_groups:\n",
    "            pg['lr'] = current_lr\n",
    "        \n",
    "        # Forward\n",
    "        x, y = data_loader.get_batch()\n",
    "        logits, loss, diags, state = model(x, y, return_diagnostics=True)\n",
    "        \n",
    "        # Backward\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        \n",
    "        # Track\n",
    "        history['loss'].append(loss.item())\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # Extract diagnostics\n",
    "        gdn_diags = [d for d in diags if d['layer_type'] == 'GDN']\n",
    "        swa_diags = [d for d in diags if d['layer_type'] == 'SWA']\n",
    "        \n",
    "        if gdn_diags:\n",
    "            history['gdn_beta'].append(gdn_diags[0]['beta_mean'])\n",
    "            history['gdn_g'].append(gdn_diags[0]['g_mean'])\n",
    "            history['state_norm'].append(gdn_diags[0]['state_norm'])\n",
    "        if swa_diags:\n",
    "            history['swa_gate'].append(swa_diags[0]['gate_mean'])\n",
    "        \n",
    "        # Log\n",
    "        if step % log_every == 0:\n",
    "            elapsed = time.time() - start\n",
    "            tps = (step + 1) * data_loader.batch_size * data_loader.seq_len / elapsed\n",
    "            avg_loss = sum(history['loss'][-50:]) / min(50, len(history['loss']))\n",
    "            \n",
    "            gdn_str = f\"β={gdn_diags[0]['beta_mean']:.3f} g={gdn_diags[0]['g_mean']:.3f}\" if gdn_diags else \"\"\n",
    "            swa_str = f\"gate={swa_diags[0]['gate_mean']:.2f}\" if swa_diags else \"\"\n",
    "            \n",
    "            print(f\"[{step:5d}] loss={avg_loss:.3f} lr={current_lr:.2e} | {gdn_str} {swa_str} | {tps:,.0f} tok/s\")\n",
    "        \n",
    "        # NIAH check\n",
    "        if (step + 1) % niah_every == 0:\n",
    "            model.eval()\n",
    "            niah = simple_niah(model, seq_len=niah_seq_len, needle_pos=niah_needle_pos, n_trials=30)\n",
    "            avg_ratio = sum(r['ratio'] for r in niah) / len(niah)\n",
    "            history['niah_ratio'].append((step + 1, avg_ratio))\n",
    "            model.train()\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"\\nTraining complete in {elapsed/60:.1f} min\")\n",
    "    print(f\"Final loss: {sum(history['loss'][-50:])/50:.3f}\")\n",
    "    \n",
    "    return dict(history)\n",
    "\n",
    "\n",
    "print(\"Training infrastructure loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7-build",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: Build & Initialize Model\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Building TransparentHybrid\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "cfg = HybridConfig(\n",
    "    d_model=256,\n",
    "    n_heads=8,\n",
    "    layer_pattern=\"GS\",\n",
    "    window_size=128,\n",
    "    state_accumulation='weighted',\n",
    "    state_weight_new=0.5,\n",
    ")\n",
    "\n",
    "model = TransparentHybrid(cfg).cuda().bfloat16()\n",
    "params = count_params(model)\n",
    "\n",
    "print(f\"\\nArchitecture: {cfg.layer_pattern}\")\n",
    "print(f\"  GDN layers: {cfg.gdn_indices}\")\n",
    "print(f\"  SWA layers: {cfg.swa_indices}\")\n",
    "print(f\"\\nParameters:\")\n",
    "print(f\"  Total: {params['total']/1e6:.2f}M\")\n",
    "print(f\"  GDN:   {params['gdn']/1e6:.2f}M\")\n",
    "print(f\"  SWA:   {params['swa']/1e6:.2f}M\")\n",
    "print(f\"  FFN:   {params['ffn']/1e6:.2f}M\")\n",
    "print(f\"  Embed: {params['embed']/1e6:.2f}M\")\n",
    "\n",
    "# Quick forward pass test\n",
    "x = torch.randint(0, 1000, (1, 128), device='cuda')\n",
    "y = torch.randint(0, 1000, (1, 128), device='cuda')\n",
    "logits, loss, diags, state = model(x, y, return_diagnostics=True)\n",
    "\n",
    "print(f\"\\nForward pass OK:\")\n",
    "print(f\"  Logits: {logits.shape}\")\n",
    "print(f\"  Loss: {loss.item():.4f}\")\n",
    "print(f\"  State: {state.shape if state is not None else None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8-pretrain-diag",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: Pre-Training Diagnostics (Optional)\n",
    "# =============================================================================\n",
    "# Run this BEFORE training to establish baseline behavior.\n",
    "# Compare with post-training diagnostics to see what changed.\n",
    "\n",
    "print(\"Pre-training diagnostic baseline:\")\n",
    "print()\n",
    "\n",
    "# Quick NIAH\n",
    "niah_pre = simple_niah(model, seq_len=128, needle_pos=32, n_trials=20)\n",
    "\n",
    "# Full diagnostic\n",
    "pre_diag = run_full_diagnostic(model, seq_len=128, needle_pos=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: Load Data\n",
    "# =============================================================================\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Loading data...\")\n",
    "ds = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\", streaming=True)\n",
    "\n",
    "# Buffer tokens\n",
    "token_buffer = []\n",
    "target_tokens = 2_000_000  # 2M tokens\n",
    "\n",
    "for doc in ds:\n",
    "    toks = tokenizer.encode(doc['text'])\n",
    "    token_buffer.extend(toks)\n",
    "    if len(token_buffer) >= target_tokens:\n",
    "        break\n",
    "\n",
    "token_tensor = torch.tensor(token_buffer[:target_tokens], device='cuda')\n",
    "print(f\"Loaded {len(token_tensor):,} tokens\")\n",
    "\n",
    "# Create data loader\n",
    "data_loader = DataLoader(token_tensor, batch_size=4, seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: Training\n",
    "# =============================================================================\n",
    "\n",
    "history = train(\n",
    "    model,\n",
    "    data_loader,\n",
    "    steps=20000,\n",
    "    lr=3e-4,\n",
    "    warmup_steps=2000,\n",
    "    log_every=100,\n",
    "    niah_every=500,\n",
    "    niah_seq_len=128,\n",
    "    niah_needle_pos=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11-postdiag",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: POST-TRAINING DIAGNOSTICS\n",
    "# =============================================================================\n",
    "# This is the critical cell. Run after training to identify the failure mode.\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# POST-TRAINING DIAGNOSTIC ANALYSIS\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "# Final NIAH at multiple positions\n",
    "print(\"\\nNIAH at different needle positions:\")\n",
    "model.eval()\n",
    "for needle_pos in [16, 32, 64, 96]:\n",
    "    niah = simple_niah(model, seq_len=128, needle_pos=needle_pos, n_trials=30)\n",
    "    avg = sum(r['ratio'] for r in niah) / len(niah)\n",
    "    print(f\"  needle@{needle_pos}: {avg:.2f}x random\")\n",
    "\n",
    "# Full diagnostic suite\n",
    "post_diag = run_full_diagnostic(model, seq_len=128, needle_pos=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: Compare Pre vs Post Training\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRE vs POST TRAINING COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# GDN State Storage\n",
    "pre_snr = pre_diag['probe1_gdn_state']['summary'].get('max_snr', 0)\n",
    "post_snr = post_diag['probe1_gdn_state']['summary'].get('max_snr', 0)\n",
    "print(f\"\\nGDN State SNR:\")\n",
    "print(f\"  Pre:  {pre_snr:.4f}\")\n",
    "print(f\"  Post: {post_snr:.4f}\")\n",
    "print(f\"  Change: {post_snr - pre_snr:+.4f}\")\n",
    "\n",
    "# SWA Attention Focus\n",
    "pre_focus = pre_diag['probe2_swa_attention']['summary'].get('avg_focus_ratio', 0)\n",
    "post_focus = post_diag['probe2_swa_attention']['summary'].get('avg_focus_ratio', 0)\n",
    "print(f\"\\nSWA Focus Ratio:\")\n",
    "print(f\"  Pre:  {pre_focus:.4f}\")\n",
    "print(f\"  Post: {post_focus:.4f}\")\n",
    "print(f\"  Change: {post_focus - pre_focus:+.4f}\")\n",
    "\n",
    "# Gate Usage\n",
    "pre_gate = pre_diag['probe2_swa_attention']['summary'].get('avg_gate', 0.5)\n",
    "post_gate = post_diag['probe2_swa_attention']['summary'].get('avg_gate', 0.5)\n",
    "print(f\"\\nSWA Gate (global usage):\")\n",
    "print(f\"  Pre:  {pre_gate:.4f}\")\n",
    "print(f\"  Post: {post_gate:.4f}\")\n",
    "print(f\"  Change: {post_gate - pre_gate:+.4f}\")\n",
    "\n",
    "# Pipeline\n",
    "pre_delta = pre_diag['probe3_pipeline']['summary'].get('total_delta', 0)\n",
    "post_delta = post_diag['probe3_pipeline']['summary'].get('total_delta', 0)\n",
    "print(f\"\\nPipeline Similarity Delta:\")\n",
    "print(f\"  Pre:  {pre_delta:+.4f}\")\n",
    "print(f\"  Post: {post_delta:+.4f}\")\n",
    "print(f\"  Change: {post_delta - pre_delta:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-next",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: Next Steps (Based on Diagnosis)\n",
    "# =============================================================================\n",
    "# \n",
    "# Based on the diagnostic results, here are the recommended fixes:\n",
    "#\n",
    "# IF GDN NOT STORING (SNR < 1.0):\n",
    "#   - Increase beta initialization: nn.init.constant_(beta_proj.bias, 1.0)\n",
    "#   - Or scale beta output: beta = 0.5 + 0.5 * sigmoid(beta_proj(x))\n",
    "#\n",
    "# IF SWA ATTENTION DIFFUSE (focus_ratio < 0.2):\n",
    "#   - Reinitialize state_k_proj with larger gain:\n",
    "#     nn.init.xavier_uniform_(state_k_proj.weight, gain=2.0)\n",
    "#   - Or add temperature scaling to global attention\n",
    "#\n",
    "# IF SWA IGNORING GLOBAL (gate < 0.3):\n",
    "#   - Initialize gate bias positive: nn.init.constant_(gate_proj.bias, 1.0)\n",
    "#   - Or switch from interpolation to concatenation + learned projection\n",
    "#\n",
    "# IF ALL METRICS OK BUT NIAH STILL FAILS:\n",
    "#   - The fusion mechanism itself may be the bottleneck\n",
    "#   - Consider replacing additive fusion with cross-attention reading\n",
    "#   - Or add a dedicated \"retrieval head\" that directly queries state\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Diagnostic complete. Review results above to determine next steps.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
